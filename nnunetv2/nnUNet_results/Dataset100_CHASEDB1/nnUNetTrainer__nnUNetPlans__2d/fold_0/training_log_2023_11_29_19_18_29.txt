
#######################################################################
Please cite the following paper when using nnU-Net:
Isensee, F., Jaeger, P. F., Kohl, S. A., Petersen, J., & Maier-Hein, K. H. (2021). nnU-Net: a self-configuring method for deep learning-based biomedical image segmentation. Nature methods, 18(2), 203-211.
#######################################################################
 

This is the configuration used by this training:
Configuration name: 2d
 {'data_identifier': 'nnUNetPlans_2d', 'preprocessor_name': 'DefaultPreprocessor', 'batch_size': 3, 'patch_size': [512, 512], 'median_image_size_in_voxels': [930.0, 930.0], 'spacing': [1.0, 1.0], 'normalization_schemes': ['ZScoreNormalization', 'ZScoreNormalization', 'ZScoreNormalization'], 'use_mask_for_norm': [False, False, False], 'UNet_class_name': 'PlainConvUNet', 'UNet_base_num_features': 32, 'n_conv_per_stage_encoder': [2, 2, 2, 2, 2, 2, 2, 2], 'n_conv_per_stage_decoder': [2, 2, 2, 2, 2, 2, 2], 'num_pool_per_axis': [7, 7], 'pool_op_kernel_sizes': [[1, 1], [2, 2], [2, 2], [2, 2], [2, 2], [2, 2], [2, 2], [2, 2]], 'conv_kernel_sizes': [[3, 3], [3, 3], [3, 3], [3, 3], [3, 3], [3, 3], [3, 3], [3, 3]], 'unet_max_num_features': 512, 'resampling_fn_data': 'resample_data_or_seg_to_shape', 'resampling_fn_seg': 'resample_data_or_seg_to_shape', 'resampling_fn_data_kwargs': {'is_seg': False, 'order': 3, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_seg_kwargs': {'is_seg': True, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_probabilities': 'resample_data_or_seg_to_shape', 'resampling_fn_probabilities_kwargs': {'is_seg': False, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'batch_dice': True} 
 
These are the global plan.json settings:
 {'dataset_name': 'Dataset100_CHASEDB1', 'plans_name': 'nnUNetPlans', 'original_median_spacing_after_transp': [999.0, 1.0, 1.0], 'original_median_shape_after_transp': [1, 930, 930], 'image_reader_writer': 'NaturalImage2DIO', 'transpose_forward': [0, 1, 2], 'transpose_backward': [0, 1, 2], 'experiment_planner_used': 'ExperimentPlanner', 'label_manager': 'LabelManager', 'foreground_intensity_properties_per_channel': {'0': {'max': 255.0, 'mean': 169.19134521484375, 'median': 163.0, 'min': 0.0, 'percentile_00_5': 36.0, 'percentile_99_5': 255.0, 'std': 58.585174560546875}, '1': {'max': 255.0, 'mean': 55.35158157348633, 'median': 52.0, 'min': 0.0, 'percentile_00_5': 6.0, 'percentile_99_5': 133.0, 'std': 24.083337783813477}, '2': {'max': 153.0, 'mean': 8.599896430969238, 'median': 7.0, 'min': 0.0, 'percentile_00_5': 0.0, 'percentile_99_5': 39.0, 'std': 8.424431800842285}}} 
 
2023-11-29 19:18:31.124276: unpacking dataset... 
2023-11-29 19:18:34.871984: unpacking done... 
2023-11-29 19:18:34.873635: do_dummy_2d_data_aug: False 
2023-11-29 19:18:34.874946: Using splits from existing split file: /home/jjf/Desktop/nnUNet/nnunetv2/nnUNet_preprocessed/Dataset100_CHASEDB1/splits_final.json 
2023-11-29 19:18:34.875396: The split file contains 5 splits. 
2023-11-29 19:18:34.875581: Desired fold for training: 0 
2023-11-29 19:18:34.875785: This split has 16 training and 4 validation cases. 
2023-11-29 19:18:34.929084: Unable to plot network architecture: 
2023-11-29 19:18:34.929318: No module named 'hiddenlayer' 
2023-11-29 19:18:34.983786:  
2023-11-29 19:18:34.984083: Epoch 0 
2023-11-29 19:18:34.984510: Current learning rate: 0.01 
2023-11-29 19:20:55.054558: train_loss -0.3342 
2023-11-29 19:20:55.054831: val_loss -0.548 
2023-11-29 19:20:55.054961: Pseudo dice [0.7643] 
2023-11-29 19:20:55.055074: Epoch time: 140.07 s 
2023-11-29 19:20:55.055213: Yayy! New best EMA pseudo Dice: 0.7643 
2023-11-29 19:20:57.687557:  
2023-11-29 19:20:57.687762: Epoch 1 
2023-11-29 19:20:57.687929: Current learning rate: 0.00999 
2023-11-29 19:24:17.083881: train_loss -0.6102 
2023-11-29 19:24:17.084142: val_loss -0.6378 
2023-11-29 19:24:17.084258: Pseudo dice [0.8052] 
2023-11-29 19:24:17.084359: Epoch time: 199.4 s 
2023-11-29 19:24:17.084454: Yayy! New best EMA pseudo Dice: 0.7684 
2023-11-29 19:24:19.699939:  
2023-11-29 19:24:19.700110: Epoch 2 
2023-11-29 19:24:19.700264: Current learning rate: 0.00998 
2023-11-29 19:28:23.579364: train_loss -0.6684 
2023-11-29 19:28:23.579564: val_loss -0.6672 
2023-11-29 19:28:23.579684: Pseudo dice [0.8214] 
2023-11-29 19:28:23.579795: Epoch time: 243.88 s 
2023-11-29 19:28:23.579896: Yayy! New best EMA pseudo Dice: 0.7737 
2023-11-29 19:28:26.308691:  
2023-11-29 19:28:26.308827: Epoch 3 
2023-11-29 19:28:26.308995: Current learning rate: 0.00997 
2023-11-29 19:32:42.801394: train_loss -0.6939 
2023-11-29 19:32:42.801676: val_loss -0.6828 
2023-11-29 19:32:42.801790: Pseudo dice [0.8282] 
2023-11-29 19:32:42.801891: Epoch time: 256.49 s 
2023-11-29 19:32:42.802010: Yayy! New best EMA pseudo Dice: 0.7791 
2023-11-29 19:32:45.561534:  
2023-11-29 19:32:45.561828: Epoch 4 
2023-11-29 19:32:45.562094: Current learning rate: 0.00996 
2023-11-29 19:36:57.451196: train_loss -0.7098 
2023-11-29 19:36:57.451428: val_loss -0.6982 
2023-11-29 19:36:57.451554: Pseudo dice [0.8364] 
2023-11-29 19:36:57.451651: Epoch time: 251.89 s 
2023-11-29 19:36:57.451737: Yayy! New best EMA pseudo Dice: 0.7849 
2023-11-29 19:37:00.158702:  
2023-11-29 19:37:00.158979: Epoch 5 
2023-11-29 19:37:00.159143: Current learning rate: 0.00995 
2023-11-29 19:41:15.837276: train_loss -0.7215 
2023-11-29 19:41:15.837527: val_loss -0.7026 
2023-11-29 19:41:15.837653: Pseudo dice [0.8389] 
2023-11-29 19:41:15.837767: Epoch time: 255.68 s 
2023-11-29 19:41:15.837860: Yayy! New best EMA pseudo Dice: 0.7903 
2023-11-29 19:41:18.610829:  
2023-11-29 19:41:18.610980: Epoch 6 
2023-11-29 19:41:18.611118: Current learning rate: 0.00995 
2023-11-29 19:45:46.174802: train_loss -0.7253 
2023-11-29 19:45:46.175032: val_loss -0.7041 
2023-11-29 19:45:46.175173: Pseudo dice [0.8395] 
2023-11-29 19:45:46.175277: Epoch time: 267.57 s 
2023-11-29 19:45:46.175378: Yayy! New best EMA pseudo Dice: 0.7952 
2023-11-29 19:45:48.887246:  
2023-11-29 19:45:48.887385: Epoch 7 
2023-11-29 19:45:48.887553: Current learning rate: 0.00994 
2023-11-29 19:50:11.772127: train_loss -0.7358 
2023-11-29 19:50:11.772582: val_loss -0.7091 
2023-11-29 19:50:11.772696: Pseudo dice [0.8424] 
2023-11-29 19:50:11.772812: Epoch time: 262.89 s 
2023-11-29 19:50:11.772924: Yayy! New best EMA pseudo Dice: 0.7999 
2023-11-29 19:50:14.520486:  
2023-11-29 19:50:14.520639: Epoch 8 
2023-11-29 19:50:14.520808: Current learning rate: 0.00993 
2023-11-29 19:54:33.533628: train_loss -0.7427 
2023-11-29 19:54:33.533918: val_loss -0.7045 
2023-11-29 19:54:33.534063: Pseudo dice [0.841] 
2023-11-29 19:54:33.534184: Epoch time: 259.01 s 
2023-11-29 19:54:33.534310: Yayy! New best EMA pseudo Dice: 0.804 
2023-11-29 19:54:36.293524:  
2023-11-29 19:54:36.293680: Epoch 9 
2023-11-29 19:54:36.293837: Current learning rate: 0.00992 
2023-11-29 19:59:21.527201: train_loss -0.7493 
2023-11-29 19:59:21.527473: val_loss -0.7078 
2023-11-29 19:59:21.527617: Pseudo dice [0.842] 
2023-11-29 19:59:21.527806: Epoch time: 285.24 s 
2023-11-29 19:59:21.527988: Yayy! New best EMA pseudo Dice: 0.8078 
2023-11-29 19:59:24.437293:  
2023-11-29 19:59:24.437591: Epoch 10 
2023-11-29 19:59:24.437772: Current learning rate: 0.00991 
2023-11-29 20:03:55.898694: train_loss -0.7563 
2023-11-29 20:03:55.898926: val_loss -0.7079 
2023-11-29 20:03:55.899066: Pseudo dice [0.8424] 
2023-11-29 20:03:55.899168: Epoch time: 271.46 s 
2023-11-29 20:03:55.899289: Yayy! New best EMA pseudo Dice: 0.8113 
2023-11-29 20:03:58.513222:  
2023-11-29 20:03:58.513503: Epoch 11 
2023-11-29 20:03:58.513693: Current learning rate: 0.0099 
2023-11-29 20:08:15.965329: train_loss -0.757 
2023-11-29 20:08:15.965572: val_loss -0.7099 
2023-11-29 20:08:15.965676: Pseudo dice [0.845] 
2023-11-29 20:08:15.965949: Epoch time: 257.45 s 
2023-11-29 20:08:15.966086: Yayy! New best EMA pseudo Dice: 0.8147 
2023-11-29 20:08:18.851240:  
2023-11-29 20:08:18.851364: Epoch 12 
2023-11-29 20:08:18.851532: Current learning rate: 0.00989 
2023-11-29 20:12:39.064815: train_loss -0.7638 
2023-11-29 20:12:39.065028: val_loss -0.712 
2023-11-29 20:12:39.065149: Pseudo dice [0.8459] 
2023-11-29 20:12:39.065255: Epoch time: 260.22 s 
2023-11-29 20:12:39.065364: Yayy! New best EMA pseudo Dice: 0.8178 
2023-11-29 20:12:41.729072:  
2023-11-29 20:12:41.729207: Epoch 13 
2023-11-29 20:12:41.729390: Current learning rate: 0.00988 
2023-11-29 20:17:04.042006: train_loss -0.7652 
2023-11-29 20:17:04.042218: val_loss -0.7105 
2023-11-29 20:17:04.042323: Pseudo dice [0.8447] 
2023-11-29 20:17:04.042417: Epoch time: 262.31 s 
2023-11-29 20:17:04.042499: Yayy! New best EMA pseudo Dice: 0.8205 
2023-11-29 20:17:06.704472:  
2023-11-29 20:17:06.704828: Epoch 14 
2023-11-29 20:17:06.705051: Current learning rate: 0.00987 
2023-11-29 20:21:26.429250: train_loss -0.7692 
2023-11-29 20:21:26.429818: val_loss -0.7117 
2023-11-29 20:21:26.430619: Pseudo dice [0.8433] 
2023-11-29 20:21:26.430752: Epoch time: 259.73 s 
2023-11-29 20:21:26.430858: Yayy! New best EMA pseudo Dice: 0.8228 
2023-11-29 20:21:29.244272:  
2023-11-29 20:21:29.244539: Epoch 15 
2023-11-29 20:21:29.244756: Current learning rate: 0.00986 
2023-11-29 20:25:47.717035: train_loss -0.7754 
2023-11-29 20:25:47.717294: val_loss -0.7062 
2023-11-29 20:25:47.717454: Pseudo dice [0.8419] 
2023-11-29 20:25:47.717553: Epoch time: 258.47 s 
2023-11-29 20:25:47.717637: Yayy! New best EMA pseudo Dice: 0.8247 
2023-11-29 20:25:50.440223:  
2023-11-29 20:25:50.440474: Epoch 16 
2023-11-29 20:25:50.440725: Current learning rate: 0.00986 
2023-11-29 20:30:07.925556: train_loss -0.7803 
2023-11-29 20:30:07.925840: val_loss -0.7025 
2023-11-29 20:30:07.925967: Pseudo dice [0.8426] 
2023-11-29 20:30:07.926084: Epoch time: 257.49 s 
2023-11-29 20:30:07.926192: Yayy! New best EMA pseudo Dice: 0.8265 
2023-11-29 20:30:10.680683:  
2023-11-29 20:30:10.680946: Epoch 17 
2023-11-29 20:30:10.681084: Current learning rate: 0.00985 
2023-11-29 20:34:32.278442: train_loss -0.7818 
2023-11-29 20:34:32.278660: val_loss -0.7055 
2023-11-29 20:34:32.278783: Pseudo dice [0.8425] 
2023-11-29 20:34:32.278885: Epoch time: 261.6 s 
2023-11-29 20:34:32.278967: Yayy! New best EMA pseudo Dice: 0.8281 
2023-11-29 20:34:35.066797:  
2023-11-29 20:34:35.066963: Epoch 18 
2023-11-29 20:34:35.067110: Current learning rate: 0.00984 
2023-11-29 20:38:53.233811: train_loss -0.7859 
2023-11-29 20:38:53.234081: val_loss -0.7043 
2023-11-29 20:38:53.234202: Pseudo dice [0.8436] 
2023-11-29 20:38:53.234298: Epoch time: 258.17 s 
2023-11-29 20:38:53.234385: Yayy! New best EMA pseudo Dice: 0.8296 
2023-11-29 20:38:56.156909:  
2023-11-29 20:38:56.157259: Epoch 19 
2023-11-29 20:38:56.157565: Current learning rate: 0.00983 
2023-11-29 20:43:29.790116: train_loss -0.7907 
2023-11-29 20:43:29.790372: val_loss -0.7105 
2023-11-29 20:43:29.790482: Pseudo dice [0.8457] 
2023-11-29 20:43:29.790579: Epoch time: 273.63 s 
2023-11-29 20:43:29.790662: Yayy! New best EMA pseudo Dice: 0.8312 
2023-11-29 20:43:32.636880:  
2023-11-29 20:43:32.637018: Epoch 20 
2023-11-29 20:43:32.637151: Current learning rate: 0.00982 
2023-11-29 20:48:08.551285: train_loss -0.7886 
2023-11-29 20:48:08.551476: val_loss -0.7101 
2023-11-29 20:48:08.551596: Pseudo dice [0.8444] 
2023-11-29 20:48:08.551687: Epoch time: 275.92 s 
2023-11-29 20:48:08.551768: Yayy! New best EMA pseudo Dice: 0.8325 
2023-11-29 20:48:11.287269:  
2023-11-29 20:48:11.287407: Epoch 21 
2023-11-29 20:48:11.287547: Current learning rate: 0.00981 
2023-11-29 20:52:52.962655: train_loss -0.7958 
2023-11-29 20:52:52.963002: val_loss -0.7111 
2023-11-29 20:52:52.964138: Pseudo dice [0.8445] 
2023-11-29 20:52:52.964368: Epoch time: 281.68 s 
2023-11-29 20:52:52.964456: Yayy! New best EMA pseudo Dice: 0.8337 
2023-11-29 20:52:55.567530:  
2023-11-29 20:52:55.567683: Epoch 22 
2023-11-29 20:52:55.567848: Current learning rate: 0.0098 
2023-11-29 20:57:33.947508: train_loss -0.7986 
2023-11-29 20:57:33.947724: val_loss -0.7108 
2023-11-29 20:57:33.947843: Pseudo dice [0.8457] 
2023-11-29 20:57:33.947937: Epoch time: 278.38 s 
2023-11-29 20:57:33.948018: Yayy! New best EMA pseudo Dice: 0.8349 
2023-11-29 20:57:36.671787:  
2023-11-29 20:57:36.671961: Epoch 23 
2023-11-29 20:57:36.672138: Current learning rate: 0.00979 
2023-11-29 21:02:13.921049: train_loss -0.7991 
2023-11-29 21:02:13.921301: val_loss -0.7072 
2023-11-29 21:02:13.922055: Pseudo dice [0.8436] 
2023-11-29 21:02:13.922175: Epoch time: 277.25 s 
2023-11-29 21:02:13.922293: Yayy! New best EMA pseudo Dice: 0.8358 
2023-11-29 21:02:16.682957:  
2023-11-29 21:02:16.683218: Epoch 24 
2023-11-29 21:02:16.683390: Current learning rate: 0.00978 
2023-11-29 21:06:57.407042: train_loss -0.8024 
2023-11-29 21:06:57.407328: val_loss -0.7087 
2023-11-29 21:06:57.407442: Pseudo dice [0.845] 
2023-11-29 21:06:57.407542: Epoch time: 280.73 s 
2023-11-29 21:06:57.407661: Yayy! New best EMA pseudo Dice: 0.8367 
2023-11-29 21:07:00.146981:  
2023-11-29 21:07:00.147120: Epoch 25 
2023-11-29 21:07:00.147296: Current learning rate: 0.00977 
2023-11-29 21:11:38.207045: train_loss -0.808 
2023-11-29 21:11:38.207280: val_loss -0.7068 
2023-11-29 21:11:38.207406: Pseudo dice [0.8449] 
2023-11-29 21:11:38.207505: Epoch time: 278.06 s 
2023-11-29 21:11:38.207593: Yayy! New best EMA pseudo Dice: 0.8375 
2023-11-29 21:11:40.902937:  
2023-11-29 21:11:40.903197: Epoch 26 
2023-11-29 21:11:40.903358: Current learning rate: 0.00977 
2023-11-29 21:16:20.736962: train_loss -0.8102 
2023-11-29 21:16:20.737216: val_loss -0.7057 
2023-11-29 21:16:20.737355: Pseudo dice [0.8444] 
2023-11-29 21:16:20.737460: Epoch time: 279.84 s 
2023-11-29 21:16:20.737548: Yayy! New best EMA pseudo Dice: 0.8382 
2023-11-29 21:16:23.424870:  
2023-11-29 21:16:23.425046: Epoch 27 
2023-11-29 21:16:23.425205: Current learning rate: 0.00976 
2023-11-29 21:21:01.132701: train_loss -0.8098 
2023-11-29 21:21:01.132902: val_loss -0.7041 
2023-11-29 21:21:01.133023: Pseudo dice [0.846] 
2023-11-29 21:21:01.133117: Epoch time: 277.71 s 
2023-11-29 21:21:01.133215: Yayy! New best EMA pseudo Dice: 0.839 
2023-11-29 21:21:03.902489:  
2023-11-29 21:21:03.902639: Epoch 28 
2023-11-29 21:21:03.902805: Current learning rate: 0.00975 
2023-11-29 21:25:46.762259: train_loss -0.8107 
2023-11-29 21:25:46.762514: val_loss -0.7068 
2023-11-29 21:25:46.762640: Pseudo dice [0.8452] 
2023-11-29 21:25:46.762738: Epoch time: 282.86 s 
2023-11-29 21:25:46.762823: Yayy! New best EMA pseudo Dice: 0.8396 
2023-11-29 21:25:49.571723:  
2023-11-29 21:25:49.572023: Epoch 29 
2023-11-29 21:25:49.572205: Current learning rate: 0.00974 
2023-11-29 21:30:32.986774: train_loss -0.8127 
2023-11-29 21:30:32.987078: val_loss -0.7141 
2023-11-29 21:30:32.987210: Pseudo dice [0.8499] 
2023-11-29 21:30:32.987324: Epoch time: 283.42 s 
2023-11-29 21:30:32.987483: Yayy! New best EMA pseudo Dice: 0.8407 
2023-11-29 21:30:35.903015:  
2023-11-29 21:30:35.903171: Epoch 30 
2023-11-29 21:30:35.903373: Current learning rate: 0.00973 
2023-11-29 21:35:25.351254: train_loss -0.819 
2023-11-29 21:35:25.351581: val_loss -0.7101 
2023-11-29 21:35:25.351708: Pseudo dice [0.8492] 
2023-11-29 21:35:25.351829: Epoch time: 289.45 s 
2023-11-29 21:35:25.351934: Yayy! New best EMA pseudo Dice: 0.8415 
2023-11-29 21:35:28.995929:  
2023-11-29 21:35:28.996181: Epoch 31 
2023-11-29 21:35:28.996419: Current learning rate: 0.00972 
2023-11-29 21:40:06.683016: train_loss -0.8165 
2023-11-29 21:40:06.683239: val_loss -0.7125 
2023-11-29 21:40:06.683376: Pseudo dice [0.8487] 
2023-11-29 21:40:06.683481: Epoch time: 277.69 s 
2023-11-29 21:40:06.683580: Yayy! New best EMA pseudo Dice: 0.8422 
2023-11-29 21:40:09.766575:  
2023-11-29 21:40:09.766811: Epoch 32 
2023-11-29 21:40:09.766964: Current learning rate: 0.00971 
2023-11-29 21:44:47.129450: train_loss -0.8218 
2023-11-29 21:44:47.129785: val_loss -0.7005 
2023-11-29 21:44:47.129894: Pseudo dice [0.8442] 
2023-11-29 21:44:47.129992: Epoch time: 277.36 s 
2023-11-29 21:44:47.130076: Yayy! New best EMA pseudo Dice: 0.8424 
2023-11-29 21:44:50.170350:  
2023-11-29 21:44:50.170496: Epoch 33 
2023-11-29 21:44:50.170639: Current learning rate: 0.0097 
2023-11-29 21:50:04.007997: train_loss -0.8213 
2023-11-29 21:50:04.009158: val_loss -0.7067 
2023-11-29 21:50:04.009267: Pseudo dice [0.8466] 
2023-11-29 21:50:04.009429: Epoch time: 313.84 s 
2023-11-29 21:50:04.009524: Yayy! New best EMA pseudo Dice: 0.8428 
2023-11-29 21:50:07.101574:  
2023-11-29 21:50:07.101909: Epoch 34 
2023-11-29 21:50:07.102129: Current learning rate: 0.00969 
2023-11-29 21:54:39.367961: train_loss -0.8248 
2023-11-29 21:54:39.368885: val_loss -0.7087 
2023-11-29 21:54:39.369014: Pseudo dice [0.8476] 
2023-11-29 21:54:39.369116: Epoch time: 272.27 s 
2023-11-29 21:54:39.369203: Yayy! New best EMA pseudo Dice: 0.8433 
2023-11-29 21:54:42.272114:  
2023-11-29 21:54:42.272278: Epoch 35 
2023-11-29 21:54:42.272443: Current learning rate: 0.00968 
2023-11-29 21:59:14.587238: train_loss -0.8259 
2023-11-29 21:59:14.588223: val_loss -0.7023 
2023-11-29 21:59:14.588341: Pseudo dice [0.8472] 
2023-11-29 21:59:14.588457: Epoch time: 272.32 s 
2023-11-29 21:59:14.588541: Yayy! New best EMA pseudo Dice: 0.8437 
2023-11-29 21:59:17.286902:  
2023-11-29 21:59:17.287179: Epoch 36 
2023-11-29 21:59:17.287375: Current learning rate: 0.00968 
2023-11-29 22:03:44.023253: train_loss -0.8264 
2023-11-29 22:03:44.024326: val_loss -0.7104 
2023-11-29 22:03:44.024468: Pseudo dice [0.8482] 
2023-11-29 22:03:44.024586: Epoch time: 266.74 s 
2023-11-29 22:03:44.024698: Yayy! New best EMA pseudo Dice: 0.8442 
2023-11-29 22:03:46.716844:  
2023-11-29 22:03:46.717141: Epoch 37 
2023-11-29 22:03:46.717402: Current learning rate: 0.00967 
2023-11-29 22:08:07.349498: train_loss -0.8309 
2023-11-29 22:08:07.349820: val_loss -0.7108 
2023-11-29 22:08:07.349924: Pseudo dice [0.8486] 
2023-11-29 22:08:07.350032: Epoch time: 260.63 s 
2023-11-29 22:08:07.350168: Yayy! New best EMA pseudo Dice: 0.8446 
2023-11-29 22:08:10.453512:  
2023-11-29 22:08:10.453829: Epoch 38 
2023-11-29 22:08:10.454008: Current learning rate: 0.00966 
2023-11-29 22:12:30.883483: train_loss -0.8303 
2023-11-29 22:12:30.883754: val_loss -0.7092 
2023-11-29 22:12:30.883868: Pseudo dice [0.8482] 
2023-11-29 22:12:30.883975: Epoch time: 260.43 s 
2023-11-29 22:12:30.884063: Yayy! New best EMA pseudo Dice: 0.845 
2023-11-29 22:12:34.394312:  
2023-11-29 22:12:34.394676: Epoch 39 
2023-11-29 22:12:34.394887: Current learning rate: 0.00965 
2023-11-29 22:16:55.664958: train_loss -0.833 
2023-11-29 22:16:55.665184: val_loss -0.7013 
2023-11-29 22:16:55.665291: Pseudo dice [0.845] 
2023-11-29 22:16:55.665448: Epoch time: 261.27 s 
2023-11-29 22:16:55.665538: Yayy! New best EMA pseudo Dice: 0.845 
2023-11-29 22:16:58.389161:  
2023-11-29 22:16:58.389590: Epoch 40 
2023-11-29 22:16:58.389796: Current learning rate: 0.00964 
2023-11-29 22:21:19.411411: train_loss -0.8376 
2023-11-29 22:21:19.411654: val_loss -0.7048 
2023-11-29 22:21:19.411779: Pseudo dice [0.8489] 
2023-11-29 22:21:19.411891: Epoch time: 261.02 s 
2023-11-29 22:21:19.411975: Yayy! New best EMA pseudo Dice: 0.8454 
2023-11-29 22:21:22.378741:  
2023-11-29 22:21:22.378895: Epoch 41 
2023-11-29 22:21:22.379064: Current learning rate: 0.00963 
2023-11-29 22:25:41.730088: train_loss -0.835 
2023-11-29 22:25:41.730362: val_loss -0.7051 
2023-11-29 22:25:41.730468: Pseudo dice [0.8482] 
2023-11-29 22:25:41.730572: Epoch time: 259.35 s 
2023-11-29 22:25:41.730679: Yayy! New best EMA pseudo Dice: 0.8456 
2023-11-29 22:25:44.740912:  
2023-11-29 22:25:44.741252: Epoch 42 
2023-11-29 22:25:44.741399: Current learning rate: 0.00962 
2023-11-29 22:30:04.186535: train_loss -0.8363 
2023-11-29 22:30:04.186773: val_loss -0.6996 
2023-11-29 22:30:04.186907: Pseudo dice [0.8446] 
2023-11-29 22:30:04.187024: Epoch time: 259.45 s 
2023-11-29 22:30:06.051375:  
2023-11-29 22:30:06.051692: Epoch 43 
2023-11-29 22:30:06.051852: Current learning rate: 0.00961 
2023-11-29 22:34:23.657776: train_loss -0.8402 
2023-11-29 22:34:23.658089: val_loss -0.7007 
2023-11-29 22:34:23.658203: Pseudo dice [0.8456] 
2023-11-29 22:34:23.658313: Epoch time: 257.61 s 
2023-11-29 22:34:25.383970:  
2023-11-29 22:34:25.384293: Epoch 44 
2023-11-29 22:34:25.384440: Current learning rate: 0.0096 
2023-11-29 22:38:43.819569: train_loss -0.8401 
2023-11-29 22:38:43.819862: val_loss -0.7003 
2023-11-29 22:38:43.820022: Pseudo dice [0.8454] 
2023-11-29 22:38:43.820124: Epoch time: 258.44 s 
2023-11-29 22:38:45.525385:  
2023-11-29 22:38:45.525534: Epoch 45 
2023-11-29 22:38:45.525668: Current learning rate: 0.00959 
2023-11-29 22:42:58.953953: train_loss -0.8415 
2023-11-29 22:42:58.954254: val_loss -0.7066 
2023-11-29 22:42:58.954382: Pseudo dice [0.8473] 
2023-11-29 22:42:58.954504: Epoch time: 253.43 s 
2023-11-29 22:42:58.954592: Yayy! New best EMA pseudo Dice: 0.8457 
2023-11-29 22:43:01.970463:  
2023-11-29 22:43:01.970617: Epoch 46 
2023-11-29 22:43:01.970749: Current learning rate: 0.00959 
2023-11-29 22:47:17.346008: train_loss -0.8411 
2023-11-29 22:47:17.346254: val_loss -0.7074 
2023-11-29 22:47:17.346384: Pseudo dice [0.849] 
2023-11-29 22:47:17.346483: Epoch time: 255.38 s 
2023-11-29 22:47:17.346568: Yayy! New best EMA pseudo Dice: 0.846 
2023-11-29 22:47:20.332072:  
2023-11-29 22:47:20.332344: Epoch 47 
2023-11-29 22:47:20.332517: Current learning rate: 0.00958 
2023-11-29 22:51:34.826241: train_loss -0.8384 
2023-11-29 22:51:34.826536: val_loss -0.6964 
2023-11-29 22:51:34.827443: Pseudo dice [0.8452] 
2023-11-29 22:51:34.827579: Epoch time: 254.5 s 
2023-11-29 22:51:36.388058:  
2023-11-29 22:51:36.388209: Epoch 48 
2023-11-29 22:51:36.388355: Current learning rate: 0.00957 
2023-11-29 22:55:50.739501: train_loss -0.8428 
2023-11-29 22:55:50.739759: val_loss -0.705 
2023-11-29 22:55:50.739882: Pseudo dice [0.8496] 
2023-11-29 22:55:50.739975: Epoch time: 254.35 s 
2023-11-29 22:55:50.740059: Yayy! New best EMA pseudo Dice: 0.8463 
2023-11-29 22:55:53.511686:  
2023-11-29 22:55:53.511966: Epoch 49 
2023-11-29 22:55:53.512161: Current learning rate: 0.00956 
2023-11-29 23:00:03.590691: train_loss -0.8463 
2023-11-29 23:00:03.590944: val_loss -0.6981 
2023-11-29 23:00:03.591053: Pseudo dice [0.8466] 
2023-11-29 23:00:03.591154: Epoch time: 250.08 s 
2023-11-29 23:00:04.034238: Yayy! New best EMA pseudo Dice: 0.8463 
2023-11-29 23:00:06.741229:  
2023-11-29 23:00:06.741404: Epoch 50 
2023-11-29 23:00:06.741566: Current learning rate: 0.00955 
2023-11-29 23:04:13.124734: train_loss -0.8445 
2023-11-29 23:04:13.124933: val_loss -0.701 
2023-11-29 23:04:13.125053: Pseudo dice [0.8485] 
2023-11-29 23:04:13.125148: Epoch time: 246.39 s 
2023-11-29 23:04:13.125230: Yayy! New best EMA pseudo Dice: 0.8466 
2023-11-29 23:04:15.751959:  
2023-11-29 23:04:15.752101: Epoch 51 
2023-11-29 23:04:15.752237: Current learning rate: 0.00954 
2023-11-29 23:08:24.782302: train_loss -0.8454 
2023-11-29 23:08:24.782520: val_loss -0.702 
2023-11-29 23:08:24.782612: Pseudo dice [0.8488] 
2023-11-29 23:08:24.782722: Epoch time: 249.03 s 
2023-11-29 23:08:24.782806: Yayy! New best EMA pseudo Dice: 0.8468 
2023-11-29 23:08:27.469214:  
2023-11-29 23:08:27.469397: Epoch 52 
2023-11-29 23:08:27.469546: Current learning rate: 0.00953 
2023-11-29 23:12:35.055985: train_loss -0.8485 
2023-11-29 23:12:35.056216: val_loss -0.7006 
2023-11-29 23:12:35.056323: Pseudo dice [0.8472] 
2023-11-29 23:12:35.056418: Epoch time: 247.59 s 
2023-11-29 23:12:35.056513: Yayy! New best EMA pseudo Dice: 0.8468 
2023-11-29 23:12:37.795591:  
2023-11-29 23:12:37.795737: Epoch 53 
2023-11-29 23:12:37.795941: Current learning rate: 0.00952 
2023-11-29 23:16:46.443628: train_loss -0.8478 
2023-11-29 23:16:46.443859: val_loss -0.7005 
2023-11-29 23:16:46.444015: Pseudo dice [0.8479] 
2023-11-29 23:16:46.444142: Epoch time: 248.65 s 
2023-11-29 23:16:46.444273: Yayy! New best EMA pseudo Dice: 0.8469 
2023-11-29 23:16:49.076937:  
2023-11-29 23:16:49.077094: Epoch 54 
2023-11-29 23:16:49.077273: Current learning rate: 0.00951 
2023-11-29 23:21:00.157900: train_loss -0.8509 
2023-11-29 23:21:00.158170: val_loss -0.6994 
2023-11-29 23:21:00.158261: Pseudo dice [0.8471] 
2023-11-29 23:21:00.158368: Epoch time: 251.08 s 
2023-11-29 23:21:00.158446: Yayy! New best EMA pseudo Dice: 0.847 
2023-11-29 23:21:02.759504:  
2023-11-29 23:21:02.759790: Epoch 55 
2023-11-29 23:21:02.759952: Current learning rate: 0.0095 
2023-11-29 23:25:09.478721: train_loss -0.8533 
2023-11-29 23:25:09.479026: val_loss -0.6957 
2023-11-29 23:25:09.479139: Pseudo dice [0.846] 
2023-11-29 23:25:09.479251: Epoch time: 246.72 s 
2023-11-29 23:25:10.912395:  
2023-11-29 23:25:10.912634: Epoch 56 
2023-11-29 23:25:10.912817: Current learning rate: 0.00949 
2023-11-29 23:29:18.186268: train_loss -0.8535 
2023-11-29 23:29:18.186514: val_loss -0.7054 
2023-11-29 23:29:18.186621: Pseudo dice [0.8503] 
2023-11-29 23:29:18.186739: Epoch time: 247.28 s 
2023-11-29 23:29:18.186838: Yayy! New best EMA pseudo Dice: 0.8472 
2023-11-29 23:29:20.840413:  
2023-11-29 23:29:20.840547: Epoch 57 
2023-11-29 23:29:20.840695: Current learning rate: 0.00949 
2023-11-29 23:33:27.071502: train_loss -0.8576 
2023-11-29 23:33:27.071699: val_loss -0.6948 
2023-11-29 23:33:27.071802: Pseudo dice [0.847] 
2023-11-29 23:33:27.071892: Epoch time: 246.23 s 
2023-11-29 23:33:28.502721:  
2023-11-29 23:33:28.503101: Epoch 58 
2023-11-29 23:33:28.503342: Current learning rate: 0.00948 
2023-11-29 23:37:33.795749: train_loss -0.8581 
2023-11-29 23:37:33.795994: val_loss -0.6972 
2023-11-29 23:37:33.796103: Pseudo dice [0.8474] 
2023-11-29 23:37:33.796200: Epoch time: 245.29 s 
2023-11-29 23:37:33.796283: Yayy! New best EMA pseudo Dice: 0.8472 
2023-11-29 23:37:36.576132:  
2023-11-29 23:37:36.576257: Epoch 59 
2023-11-29 23:37:36.576417: Current learning rate: 0.00947 
2023-11-29 23:41:37.104408: train_loss -0.857 
2023-11-29 23:41:37.104671: val_loss -0.6967 
2023-11-29 23:41:37.104792: Pseudo dice [0.8464] 
2023-11-29 23:41:37.104887: Epoch time: 240.53 s 
2023-11-29 23:41:38.615593:  
2023-11-29 23:41:38.615981: Epoch 60 
2023-11-29 23:41:38.616241: Current learning rate: 0.00946 
2023-11-29 23:45:41.355350: train_loss -0.8583 
2023-11-29 23:45:41.355604: val_loss -0.6947 
2023-11-29 23:45:41.355728: Pseudo dice [0.8471] 
2023-11-29 23:45:41.355824: Epoch time: 242.74 s 
2023-11-29 23:45:42.771921:  
2023-11-29 23:45:42.772314: Epoch 61 
2023-11-29 23:45:42.772568: Current learning rate: 0.00945 
2023-11-29 23:49:47.770181: train_loss -0.8551 
2023-11-29 23:49:47.770416: val_loss -0.6972 
2023-11-29 23:49:47.770523: Pseudo dice [0.8473] 
2023-11-29 23:49:47.770618: Epoch time: 245.0 s 
2023-11-29 23:49:49.272920:  
2023-11-29 23:49:49.273295: Epoch 62 
2023-11-29 23:49:49.273559: Current learning rate: 0.00944 
2023-11-29 23:53:50.805122: train_loss -0.857 
2023-11-29 23:53:50.805388: val_loss -0.6957 
2023-11-29 23:53:50.805505: Pseudo dice [0.8437] 
2023-11-29 23:53:50.805605: Epoch time: 241.53 s 
2023-11-29 23:53:52.266971:  
2023-11-29 23:53:52.267173: Epoch 63 
2023-11-29 23:53:52.267370: Current learning rate: 0.00943 
2023-11-29 23:57:54.304047: train_loss -0.8561 
2023-11-29 23:57:54.304318: val_loss -0.6934 
2023-11-29 23:57:54.304458: Pseudo dice [0.8468] 
2023-11-29 23:57:54.304555: Epoch time: 242.04 s 
2023-11-29 23:57:55.908804:  
2023-11-29 23:57:55.909069: Epoch 64 
2023-11-29 23:57:55.909300: Current learning rate: 0.00942 
2023-11-30 00:02:01.822078: train_loss -0.863 
2023-11-30 00:02:01.822294: val_loss -0.6972 
2023-11-30 00:02:01.822416: Pseudo dice [0.848] 
2023-11-30 00:02:01.822510: Epoch time: 245.91 s 
2023-11-30 00:02:03.253155:  
2023-11-30 00:02:03.253453: Epoch 65 
2023-11-30 00:02:03.253846: Current learning rate: 0.00941 
2023-11-30 00:06:06.768970: train_loss -0.8634 
2023-11-30 00:06:06.769196: val_loss -0.6941 
2023-11-30 00:06:06.769332: Pseudo dice [0.8468] 
2023-11-30 00:06:06.769466: Epoch time: 243.52 s 
2023-11-30 00:06:08.216473:  
2023-11-30 00:06:08.216611: Epoch 66 
2023-11-30 00:06:08.216762: Current learning rate: 0.0094 
2023-11-30 00:10:07.084502: train_loss -0.8607 
2023-11-30 00:10:07.084754: val_loss -0.6932 
2023-11-30 00:10:07.084911: Pseudo dice [0.8461] 
2023-11-30 00:10:07.085026: Epoch time: 238.87 s 
2023-11-30 00:10:08.556890:  
2023-11-30 00:10:08.557169: Epoch 67 
2023-11-30 00:10:08.557473: Current learning rate: 0.00939 
2023-11-30 00:14:12.583838: train_loss -0.8646 
2023-11-30 00:14:12.584051: val_loss -0.6867 
2023-11-30 00:14:12.584174: Pseudo dice [0.8468] 
2023-11-30 00:14:12.584279: Epoch time: 244.03 s 
2023-11-30 00:14:14.075482:  
2023-11-30 00:14:14.075616: Epoch 68 
2023-11-30 00:14:14.075765: Current learning rate: 0.00939 
2023-11-30 00:18:14.307122: train_loss -0.8612 
2023-11-30 00:18:14.307357: val_loss -0.6903 
2023-11-30 00:18:14.307482: Pseudo dice [0.8436] 
2023-11-30 00:18:14.307588: Epoch time: 240.23 s 
2023-11-30 00:18:15.924591:  
2023-11-30 00:18:15.924733: Epoch 69 
2023-11-30 00:18:15.924880: Current learning rate: 0.00938 
2023-11-30 00:22:20.539372: train_loss -0.8624 
2023-11-30 00:22:20.539613: val_loss -0.6921 
2023-11-30 00:22:20.539723: Pseudo dice [0.8467] 
2023-11-30 00:22:20.539844: Epoch time: 244.62 s 
2023-11-30 00:22:22.024958:  
2023-11-30 00:22:22.025094: Epoch 70 
2023-11-30 00:22:22.025249: Current learning rate: 0.00937 
2023-11-30 00:26:28.135923: train_loss -0.8629 
2023-11-30 00:26:28.136137: val_loss -0.6912 
2023-11-30 00:26:28.136243: Pseudo dice [0.8456] 
2023-11-30 00:26:28.136343: Epoch time: 246.11 s 
2023-11-30 00:26:29.628695:  
2023-11-30 00:26:29.628958: Epoch 71 
2023-11-30 00:26:29.629157: Current learning rate: 0.00936 
2023-11-30 00:30:29.533801: train_loss -0.8683 
2023-11-30 00:30:29.534028: val_loss -0.6847 
2023-11-30 00:30:29.534141: Pseudo dice [0.8461] 
2023-11-30 00:30:29.534240: Epoch time: 239.91 s 
2023-11-30 00:30:31.026094:  
2023-11-30 00:30:31.026331: Epoch 72 
2023-11-30 00:30:31.026603: Current learning rate: 0.00935 
2023-11-30 00:34:31.173488: train_loss -0.8652 
2023-11-30 00:34:31.173729: val_loss -0.6926 
2023-11-30 00:34:31.173835: Pseudo dice [0.8487] 
2023-11-30 00:34:31.173927: Epoch time: 240.15 s 
2023-11-30 00:34:32.621429:  
2023-11-30 00:34:32.621559: Epoch 73 
2023-11-30 00:34:32.621681: Current learning rate: 0.00934 
2023-11-30 00:38:34.791039: train_loss -0.8661 
2023-11-30 00:38:34.791270: val_loss -0.6925 
2023-11-30 00:38:34.791377: Pseudo dice [0.8482] 
2023-11-30 00:38:34.791473: Epoch time: 242.17 s 
2023-11-30 00:38:36.433091:  
2023-11-30 00:38:36.433211: Epoch 74 
2023-11-30 00:38:36.433414: Current learning rate: 0.00933 
2023-11-30 00:42:36.700904: train_loss -0.8712 
2023-11-30 00:42:36.701168: val_loss -0.6945 
2023-11-30 00:42:36.701347: Pseudo dice [0.8479] 
2023-11-30 00:42:36.701456: Epoch time: 240.27 s 
2023-11-30 00:42:38.217919:  
2023-11-30 00:42:38.218103: Epoch 75 
2023-11-30 00:42:38.218261: Current learning rate: 0.00932 
2023-11-30 00:46:36.789784: train_loss -0.8696 
2023-11-30 00:46:36.790014: val_loss -0.6873 
2023-11-30 00:46:36.790143: Pseudo dice [0.8461] 
2023-11-30 00:46:36.790257: Epoch time: 238.57 s 
2023-11-30 00:46:38.286891:  
2023-11-30 00:46:38.287032: Epoch 76 
2023-11-30 00:46:38.287181: Current learning rate: 0.00931 
2023-11-30 00:50:38.967559: train_loss -0.8712 
2023-11-30 00:50:38.967770: val_loss -0.6938 
2023-11-30 00:50:38.967897: Pseudo dice [0.8488] 
2023-11-30 00:50:38.967993: Epoch time: 240.68 s 
2023-11-30 00:50:40.471134:  
2023-11-30 00:50:40.471273: Epoch 77 
2023-11-30 00:50:40.471462: Current learning rate: 0.0093 
2023-11-30 00:54:41.991714: train_loss -0.8708 
2023-11-30 00:54:41.991961: val_loss -0.6883 
2023-11-30 00:54:41.992081: Pseudo dice [0.8459] 
2023-11-30 00:54:41.992177: Epoch time: 241.52 s 
2023-11-30 00:54:43.536833:  
2023-11-30 00:54:43.537001: Epoch 78 
2023-11-30 00:54:43.537288: Current learning rate: 0.0093 
2023-11-30 00:58:41.595054: train_loss -0.8702 
2023-11-30 00:58:41.595258: val_loss -0.693 
2023-11-30 00:58:41.595395: Pseudo dice [0.8486] 
2023-11-30 00:58:41.595489: Epoch time: 238.06 s 
2023-11-30 00:58:43.249387:  
2023-11-30 00:58:43.249744: Epoch 79 
2023-11-30 00:58:43.249974: Current learning rate: 0.00929 
2023-11-30 01:02:38.518497: train_loss -0.8674 
2023-11-30 01:02:38.518737: val_loss -0.6977 
2023-11-30 01:02:38.518860: Pseudo dice [0.8491] 
2023-11-30 01:02:38.518957: Epoch time: 235.27 s 
2023-11-30 01:02:38.519041: Yayy! New best EMA pseudo Dice: 0.8473 
2023-11-30 01:02:41.254639:  
2023-11-30 01:02:41.254899: Epoch 80 
2023-11-30 01:02:41.255122: Current learning rate: 0.00928 
2023-11-30 01:06:37.440915: train_loss -0.8672 
2023-11-30 01:06:37.441263: val_loss -0.6893 
2023-11-30 01:06:37.441460: Pseudo dice [0.8471] 
2023-11-30 01:06:37.441591: Epoch time: 236.19 s 
2023-11-30 01:06:38.999549:  
2023-11-30 01:06:38.999706: Epoch 81 
2023-11-30 01:06:38.999841: Current learning rate: 0.00927 
2023-11-30 01:10:39.597977: train_loss -0.8732 
2023-11-30 01:10:39.598190: val_loss -0.6875 
2023-11-30 01:10:39.598311: Pseudo dice [0.8467] 
2023-11-30 01:10:39.598407: Epoch time: 240.6 s 
2023-11-30 01:10:41.093544:  
2023-11-30 01:10:41.093713: Epoch 82 
2023-11-30 01:10:41.093876: Current learning rate: 0.00926 
2023-11-30 01:14:41.122018: train_loss -0.8769 
2023-11-30 01:14:41.122229: val_loss -0.691 
2023-11-30 01:14:41.122334: Pseudo dice [0.8488] 
2023-11-30 01:14:41.122428: Epoch time: 240.03 s 
2023-11-30 01:14:41.122508: Yayy! New best EMA pseudo Dice: 0.8474 
2023-11-30 01:14:43.747093:  
2023-11-30 01:14:43.747537: Epoch 83 
2023-11-30 01:14:43.747786: Current learning rate: 0.00925 
2023-11-30 01:18:38.679105: train_loss -0.8735 
2023-11-30 01:18:38.679335: val_loss -0.6876 
2023-11-30 01:18:38.679441: Pseudo dice [0.8474] 
2023-11-30 01:18:38.679536: Epoch time: 234.93 s 
2023-11-30 01:18:38.679618: Yayy! New best EMA pseudo Dice: 0.8474 
2023-11-30 01:18:41.422226:  
2023-11-30 01:18:41.422354: Epoch 84 
2023-11-30 01:18:41.422504: Current learning rate: 0.00924 
2023-11-30 01:22:38.863059: train_loss -0.8752 
2023-11-30 01:22:38.863314: val_loss -0.6843 
2023-11-30 01:22:38.863426: Pseudo dice [0.8464] 
2023-11-30 01:22:38.863523: Epoch time: 237.44 s 
2023-11-30 01:22:40.250320:  
2023-11-30 01:22:40.250445: Epoch 85 
2023-11-30 01:22:40.250589: Current learning rate: 0.00923 
2023-11-30 01:26:40.001048: train_loss -0.8746 
2023-11-30 01:26:40.001285: val_loss -0.6856 
2023-11-30 01:26:40.001437: Pseudo dice [0.8463] 
2023-11-30 01:26:40.001537: Epoch time: 239.75 s 
2023-11-30 01:26:41.439605:  
2023-11-30 01:26:41.439746: Epoch 86 
2023-11-30 01:26:41.439896: Current learning rate: 0.00922 
2023-11-30 01:30:38.193138: train_loss -0.8735 
2023-11-30 01:30:38.193404: val_loss -0.6903 
2023-11-30 01:30:38.193520: Pseudo dice [0.8451] 
2023-11-30 01:30:38.193816: Epoch time: 236.76 s 
2023-11-30 01:30:39.616626:  
2023-11-30 01:30:39.616784: Epoch 87 
2023-11-30 01:30:39.616966: Current learning rate: 0.00921 
2023-11-30 01:34:34.448593: train_loss -0.8759 
2023-11-30 01:34:34.448809: val_loss -0.6808 
2023-11-30 01:34:34.448929: Pseudo dice [0.8459] 
2023-11-30 01:34:34.449024: Epoch time: 234.83 s 
2023-11-30 01:34:35.833329:  
2023-11-30 01:34:35.833466: Epoch 88 
2023-11-30 01:34:35.833648: Current learning rate: 0.0092 
2023-11-30 01:38:30.177833: train_loss -0.8739 
2023-11-30 01:38:30.178045: val_loss -0.6814 
2023-11-30 01:38:30.178168: Pseudo dice [0.8431] 
2023-11-30 01:38:30.178262: Epoch time: 234.35 s 
2023-11-30 01:38:31.609489:  
2023-11-30 01:38:31.609611: Epoch 89 
2023-11-30 01:38:31.609775: Current learning rate: 0.0092 
2023-11-30 01:42:28.926715: train_loss -0.8778 
2023-11-30 01:42:28.926940: val_loss -0.6824 
2023-11-30 01:42:28.927047: Pseudo dice [0.8475] 
2023-11-30 01:42:28.927158: Epoch time: 237.32 s 
2023-11-30 01:42:30.363617:  
2023-11-30 01:42:30.363950: Epoch 90 
2023-11-30 01:42:30.364142: Current learning rate: 0.00919 
2023-11-30 01:46:26.504032: train_loss -0.8798 
2023-11-30 01:46:26.504244: val_loss -0.6862 
2023-11-30 01:46:26.504364: Pseudo dice [0.8456] 
2023-11-30 01:46:26.504462: Epoch time: 236.14 s 
2023-11-30 01:46:27.923107:  
2023-11-30 01:46:27.923232: Epoch 91 
2023-11-30 01:46:27.923395: Current learning rate: 0.00918 
2023-11-30 01:50:21.429422: train_loss -0.8794 
2023-11-30 01:50:21.429648: val_loss -0.6846 
2023-11-30 01:50:21.429769: Pseudo dice [0.8458] 
2023-11-30 01:50:21.429863: Epoch time: 233.51 s 
2023-11-30 01:50:22.806145:  
2023-11-30 01:50:22.806299: Epoch 92 
2023-11-30 01:50:22.806472: Current learning rate: 0.00917 
2023-11-30 01:54:16.454595: train_loss -0.8791 
2023-11-30 01:54:16.454802: val_loss -0.6904 
2023-11-30 01:54:16.454932: Pseudo dice [0.8491] 
2023-11-30 01:54:16.455029: Epoch time: 233.65 s 
2023-11-30 01:54:17.825508:  
2023-11-30 01:54:17.825826: Epoch 93 
2023-11-30 01:54:17.826076: Current learning rate: 0.00916 
2023-11-30 01:58:08.946967: train_loss -0.8769 
2023-11-30 01:58:08.947216: val_loss -0.6872 
2023-11-30 01:58:08.947324: Pseudo dice [0.8461] 
2023-11-30 01:58:08.947418: Epoch time: 231.12 s 
2023-11-30 01:58:10.305709:  
2023-11-30 01:58:10.305857: Epoch 94 
2023-11-30 01:58:10.306009: Current learning rate: 0.00915 
2023-11-30 02:02:02.609397: train_loss -0.8748 
2023-11-30 02:02:02.609646: val_loss -0.6838 
2023-11-30 02:02:02.609785: Pseudo dice [0.8456] 
2023-11-30 02:02:02.609880: Epoch time: 232.31 s 
2023-11-30 02:02:04.195767:  
2023-11-30 02:02:04.196019: Epoch 95 
2023-11-30 02:02:04.196274: Current learning rate: 0.00914 
2023-11-30 02:05:57.260721: train_loss -0.8779 
2023-11-30 02:05:57.261077: val_loss -0.6888 
2023-11-30 02:05:57.261310: Pseudo dice [0.8485] 
2023-11-30 02:05:57.261457: Epoch time: 233.07 s 
2023-11-30 02:05:58.649042:  
2023-11-30 02:05:58.649374: Epoch 96 
2023-11-30 02:05:58.649544: Current learning rate: 0.00913 
2023-11-30 02:09:52.913028: train_loss -0.8772 
2023-11-30 02:09:52.913276: val_loss -0.6808 
2023-11-30 02:09:52.913430: Pseudo dice [0.8467] 
2023-11-30 02:09:52.913541: Epoch time: 234.27 s 
2023-11-30 02:09:54.337742:  
2023-11-30 02:09:54.338106: Epoch 97 
2023-11-30 02:09:54.338353: Current learning rate: 0.00912 
2023-11-30 02:13:49.299444: train_loss -0.8817 
2023-11-30 02:13:49.299684: val_loss -0.6866 
2023-11-30 02:13:49.299804: Pseudo dice [0.8473] 
2023-11-30 02:13:49.299928: Epoch time: 234.96 s 
2023-11-30 02:13:50.700917:  
2023-11-30 02:13:50.701073: Epoch 98 
2023-11-30 02:13:50.701254: Current learning rate: 0.00911 
2023-11-30 02:17:45.185922: train_loss -0.8815 
2023-11-30 02:17:45.186181: val_loss -0.6871 
2023-11-30 02:17:45.186291: Pseudo dice [0.8461] 
2023-11-30 02:17:45.186435: Epoch time: 234.49 s 
2023-11-30 02:17:46.606825:  
2023-11-30 02:17:46.606947: Epoch 99 
2023-11-30 02:17:46.607115: Current learning rate: 0.0091 
2023-11-30 02:21:42.465870: train_loss -0.8818 
2023-11-30 02:21:42.466081: val_loss -0.6883 
2023-11-30 02:21:42.466205: Pseudo dice [0.8465] 
2023-11-30 02:21:42.466303: Epoch time: 235.86 s 
2023-11-30 02:21:45.272285:  
2023-11-30 02:21:45.272507: Epoch 100 
2023-11-30 02:21:45.272751: Current learning rate: 0.0091 
2023-11-30 02:25:37.080996: train_loss -0.8813 
2023-11-30 02:25:37.081214: val_loss -0.6776 
2023-11-30 02:25:37.081388: Pseudo dice [0.8453] 
2023-11-30 02:25:37.081506: Epoch time: 231.81 s 
2023-11-30 02:25:38.508474:  
2023-11-30 02:25:38.508622: Epoch 101 
2023-11-30 02:25:38.508807: Current learning rate: 0.00909 
2023-11-30 02:29:33.702632: train_loss -0.8812 
2023-11-30 02:29:33.702845: val_loss -0.681 
2023-11-30 02:29:33.702967: Pseudo dice [0.8468] 
2023-11-30 02:29:33.703061: Epoch time: 235.2 s 
2023-11-30 02:29:35.124488:  
2023-11-30 02:29:35.124626: Epoch 102 
2023-11-30 02:29:35.124790: Current learning rate: 0.00908 
2023-11-30 02:33:29.088550: train_loss -0.8826 
2023-11-30 02:33:29.088792: val_loss -0.6762 
2023-11-30 02:33:29.088915: Pseudo dice [0.8452] 
2023-11-30 02:33:29.089013: Epoch time: 233.97 s 
2023-11-30 02:33:30.550216:  
2023-11-30 02:33:30.550554: Epoch 103 
2023-11-30 02:33:30.550813: Current learning rate: 0.00907 
2023-11-30 02:37:23.376413: train_loss -0.8802 
2023-11-30 02:37:23.376683: val_loss -0.6876 
2023-11-30 02:37:23.376832: Pseudo dice [0.848] 
2023-11-30 02:37:23.376947: Epoch time: 232.83 s 
2023-11-30 02:37:24.801163:  
2023-11-30 02:37:24.801283: Epoch 104 
2023-11-30 02:37:24.801471: Current learning rate: 0.00906 
2023-11-30 02:41:14.753877: train_loss -0.8792 
2023-11-30 02:41:14.754104: val_loss -0.6907 
2023-11-30 02:41:14.754239: Pseudo dice [0.8516] 
2023-11-30 02:41:14.754333: Epoch time: 229.95 s 
2023-11-30 02:41:16.187443:  
2023-11-30 02:41:16.187576: Epoch 105 
2023-11-30 02:41:16.187709: Current learning rate: 0.00905 
2023-11-30 02:45:10.329183: train_loss -0.882 
2023-11-30 02:45:10.329435: val_loss -0.6814 
2023-11-30 02:45:10.329547: Pseudo dice [0.8485] 
2023-11-30 02:45:10.329645: Epoch time: 234.14 s 
2023-11-30 02:45:11.905355:  
2023-11-30 02:45:11.905486: Epoch 106 
2023-11-30 02:45:11.905640: Current learning rate: 0.00904 
2023-11-30 02:48:59.224599: train_loss -0.8833 
2023-11-30 02:48:59.224852: val_loss -0.6827 
2023-11-30 02:48:59.224962: Pseudo dice [0.8479] 
2023-11-30 02:48:59.225055: Epoch time: 227.32 s 
2023-11-30 02:49:00.671515:  
2023-11-30 02:49:00.671668: Epoch 107 
2023-11-30 02:49:00.671821: Current learning rate: 0.00903 
2023-11-30 02:52:53.121852: train_loss -0.8834 
2023-11-30 02:52:53.122086: val_loss -0.6836 
2023-11-30 02:52:53.122230: Pseudo dice [0.8427] 
2023-11-30 02:52:53.122333: Epoch time: 232.45 s 
2023-11-30 02:52:54.552830:  
2023-11-30 02:52:54.552954: Epoch 108 
2023-11-30 02:52:54.553116: Current learning rate: 0.00902 
2023-11-30 02:56:44.761620: train_loss -0.8866 
2023-11-30 02:56:44.761848: val_loss -0.6853 
2023-11-30 02:56:44.761943: Pseudo dice [0.8492] 
2023-11-30 02:56:44.762042: Epoch time: 230.21 s 
2023-11-30 02:56:46.223597:  
2023-11-30 02:56:46.223732: Epoch 109 
2023-11-30 02:56:46.223881: Current learning rate: 0.00901 
2023-11-30 03:00:37.393759: train_loss -0.8848 
2023-11-30 03:00:37.394006: val_loss -0.6827 
2023-11-30 03:00:37.394114: Pseudo dice [0.844] 
2023-11-30 03:00:37.394209: Epoch time: 231.17 s 
2023-11-30 03:00:38.798587:  
2023-11-30 03:00:38.798738: Epoch 110 
2023-11-30 03:00:38.798872: Current learning rate: 0.009 
2023-11-30 03:04:28.898919: train_loss -0.8832 
2023-11-30 03:04:28.899183: val_loss -0.6835 
2023-11-30 03:04:28.899339: Pseudo dice [0.8473] 
2023-11-30 03:04:28.899466: Epoch time: 230.1 s 
2023-11-30 03:04:30.472945:  
2023-11-30 03:04:30.473068: Epoch 111 
2023-11-30 03:04:30.473238: Current learning rate: 0.009 
2023-11-30 03:08:23.862127: train_loss -0.8869 
2023-11-30 03:08:23.862362: val_loss -0.6782 
2023-11-30 03:08:23.862468: Pseudo dice [0.8445] 
2023-11-30 03:08:23.862561: Epoch time: 233.39 s 
2023-11-30 03:08:25.272917:  
2023-11-30 03:08:25.273058: Epoch 112 
2023-11-30 03:08:25.273209: Current learning rate: 0.00899 
2023-11-30 03:12:14.611192: train_loss -0.8873 
2023-11-30 03:12:14.611410: val_loss -0.6759 
2023-11-30 03:12:14.611531: Pseudo dice [0.8469] 
2023-11-30 03:12:14.611626: Epoch time: 229.34 s 
2023-11-30 03:12:16.062722:  
2023-11-30 03:12:16.062860: Epoch 113 
2023-11-30 03:12:16.062994: Current learning rate: 0.00898 
2023-11-30 03:16:06.587887: train_loss -0.8893 
2023-11-30 03:16:06.588119: val_loss -0.6819 
2023-11-30 03:16:06.588242: Pseudo dice [0.8484] 
2023-11-30 03:16:06.588352: Epoch time: 230.53 s 
2023-11-30 03:16:08.043168:  
2023-11-30 03:16:08.043305: Epoch 114 
2023-11-30 03:16:08.043438: Current learning rate: 0.00897 
2023-11-30 03:19:55.969895: train_loss -0.8854 
2023-11-30 03:19:55.970095: val_loss -0.6778 
2023-11-30 03:19:55.970218: Pseudo dice [0.8496] 
2023-11-30 03:19:55.970313: Epoch time: 227.93 s 
2023-11-30 03:19:57.425793:  
2023-11-30 03:19:57.425950: Epoch 115 
2023-11-30 03:19:57.426102: Current learning rate: 0.00896 
2023-11-30 03:23:44.678165: train_loss -0.8894 
2023-11-30 03:23:44.678403: val_loss -0.6841 
2023-11-30 03:23:44.678512: Pseudo dice [0.849] 
2023-11-30 03:23:44.678607: Epoch time: 227.25 s 
2023-11-30 03:23:46.214526:  
2023-11-30 03:23:46.214678: Epoch 116 
2023-11-30 03:23:46.214817: Current learning rate: 0.00895 
2023-11-30 03:27:36.155469: train_loss -0.8884 
2023-11-30 03:27:36.155687: val_loss -0.6809 
2023-11-30 03:27:36.155807: Pseudo dice [0.8459] 
2023-11-30 03:27:36.155902: Epoch time: 229.94 s 
2023-11-30 03:27:37.766238:  
2023-11-30 03:27:37.766376: Epoch 117 
2023-11-30 03:27:37.766524: Current learning rate: 0.00894 
2023-11-30 03:31:30.330805: train_loss -0.8844 
2023-11-30 03:31:30.331035: val_loss -0.678 
2023-11-30 03:31:30.331125: Pseudo dice [0.8459] 
2023-11-30 03:31:30.331217: Epoch time: 232.57 s 
2023-11-30 03:31:31.796985:  
2023-11-30 03:31:31.797114: Epoch 118 
2023-11-30 03:31:31.797259: Current learning rate: 0.00893 
2023-11-30 03:35:19.266510: train_loss -0.8894 
2023-11-30 03:35:19.266697: val_loss -0.6753 
2023-11-30 03:35:19.266817: Pseudo dice [0.8479] 
2023-11-30 03:35:19.266928: Epoch time: 227.47 s 
2023-11-30 03:35:20.732734:  
2023-11-30 03:35:20.732852: Epoch 119 
2023-11-30 03:35:20.732983: Current learning rate: 0.00892 
2023-11-30 03:39:08.437946: train_loss -0.8868 
2023-11-30 03:39:08.438221: val_loss -0.677 
2023-11-30 03:39:08.438329: Pseudo dice [0.845] 
2023-11-30 03:39:08.438424: Epoch time: 227.71 s 
2023-11-30 03:39:09.876236:  
2023-11-30 03:39:09.876374: Epoch 120 
2023-11-30 03:39:09.876553: Current learning rate: 0.00891 
2023-11-30 03:42:54.603316: train_loss -0.8889 
2023-11-30 03:42:54.603557: val_loss -0.6722 
2023-11-30 03:42:54.603663: Pseudo dice [0.8428] 
2023-11-30 03:42:54.603758: Epoch time: 224.73 s 
2023-11-30 03:42:56.041497:  
2023-11-30 03:42:56.041667: Epoch 121 
2023-11-30 03:42:56.041831: Current learning rate: 0.0089 
2023-11-30 03:46:42.022625: train_loss -0.8891 
2023-11-30 03:46:42.022863: val_loss -0.6768 
2023-11-30 03:46:42.022980: Pseudo dice [0.8457] 
2023-11-30 03:46:42.023120: Epoch time: 225.98 s 
2023-11-30 03:46:43.637775:  
2023-11-30 03:46:43.637920: Epoch 122 
2023-11-30 03:46:43.638069: Current learning rate: 0.00889 
2023-11-30 03:50:31.216362: train_loss -0.8905 
2023-11-30 03:50:31.216586: val_loss -0.6764 
2023-11-30 03:50:31.216707: Pseudo dice [0.8461] 
2023-11-30 03:50:31.216802: Epoch time: 227.58 s 
2023-11-30 03:50:32.691793:  
2023-11-30 03:50:32.691934: Epoch 123 
2023-11-30 03:50:32.692135: Current learning rate: 0.00889 
2023-11-30 03:54:24.230839: train_loss -0.8936 
2023-11-30 03:54:24.231088: val_loss -0.6807 
2023-11-30 03:54:24.231196: Pseudo dice [0.8486] 
2023-11-30 03:54:24.231290: Epoch time: 231.54 s 
2023-11-30 03:54:25.748995:  
2023-11-30 03:54:25.749280: Epoch 124 
2023-11-30 03:54:25.749479: Current learning rate: 0.00888 
2023-11-30 03:58:10.926659: train_loss -0.8895 
2023-11-30 03:58:10.926879: val_loss -0.6737 
2023-11-30 03:58:10.927001: Pseudo dice [0.8445] 
2023-11-30 03:58:10.927097: Epoch time: 225.18 s 
2023-11-30 03:58:12.365214:  
2023-11-30 03:58:12.365510: Epoch 125 
2023-11-30 03:58:12.365699: Current learning rate: 0.00887 
2023-11-30 04:01:59.727400: train_loss -0.8917 
2023-11-30 04:01:59.727621: val_loss -0.6877 
2023-11-30 04:01:59.727726: Pseudo dice [0.8491] 
2023-11-30 04:01:59.727818: Epoch time: 227.36 s 
2023-11-30 04:02:01.177036:  
2023-11-30 04:02:01.177169: Epoch 126 
2023-11-30 04:02:01.177325: Current learning rate: 0.00886 
2023-11-30 04:05:47.569284: train_loss -0.8892 
2023-11-30 04:05:47.569761: val_loss -0.6811 
2023-11-30 04:05:47.569870: Pseudo dice [0.846] 
2023-11-30 04:05:47.569968: Epoch time: 226.39 s 
2023-11-30 04:05:49.157803:  
2023-11-30 04:05:49.157960: Epoch 127 
2023-11-30 04:05:49.158121: Current learning rate: 0.00885 
2023-11-30 04:09:32.431039: train_loss -0.8902 
2023-11-30 04:09:32.431267: val_loss -0.6722 
2023-11-30 04:09:32.431391: Pseudo dice [0.8481] 
2023-11-30 04:09:32.431486: Epoch time: 223.27 s 
2023-11-30 04:09:33.871798:  
2023-11-30 04:09:33.871915: Epoch 128 
2023-11-30 04:09:33.872066: Current learning rate: 0.00884 
2023-11-30 04:13:23.451051: train_loss -0.8899 
2023-11-30 04:13:23.451242: val_loss -0.6748 
2023-11-30 04:13:23.451347: Pseudo dice [0.8473] 
2023-11-30 04:13:23.451442: Epoch time: 229.58 s 
2023-11-30 04:13:24.976775:  
2023-11-30 04:13:24.976895: Epoch 129 
2023-11-30 04:13:24.977058: Current learning rate: 0.00883 
2023-11-30 04:17:11.756311: train_loss -0.8918 
2023-11-30 04:17:11.756548: val_loss -0.687 
2023-11-30 04:17:11.756672: Pseudo dice [0.8492] 
2023-11-30 04:17:11.756770: Epoch time: 226.78 s 
2023-11-30 04:17:13.202555:  
2023-11-30 04:17:13.202692: Epoch 130 
2023-11-30 04:17:13.202838: Current learning rate: 0.00882 
2023-11-30 04:21:00.961190: train_loss -0.8912 
2023-11-30 04:21:00.961447: val_loss -0.6819 
2023-11-30 04:21:00.961576: Pseudo dice [0.8481] 
2023-11-30 04:21:00.961728: Epoch time: 227.76 s 
2023-11-30 04:21:02.396211:  
2023-11-30 04:21:02.396348: Epoch 131 
2023-11-30 04:21:02.396533: Current learning rate: 0.00881 
2023-11-30 04:24:50.495767: train_loss -0.894 
2023-11-30 04:24:50.495980: val_loss -0.6913 
2023-11-30 04:24:50.496103: Pseudo dice [0.8479] 
2023-11-30 04:24:50.496196: Epoch time: 228.1 s 
2023-11-30 04:24:52.083310:  
2023-11-30 04:24:52.083449: Epoch 132 
2023-11-30 04:24:52.083603: Current learning rate: 0.0088 
2023-11-30 04:28:38.344360: train_loss -0.8895 
2023-11-30 04:28:38.344654: val_loss -0.6774 
2023-11-30 04:28:38.345387: Pseudo dice [0.849] 
2023-11-30 04:28:38.345498: Epoch time: 226.26 s 
2023-11-30 04:28:38.345592: Yayy! New best EMA pseudo Dice: 0.8474 
2023-11-30 04:28:41.018608:  
2023-11-30 04:28:41.018732: Epoch 133 
2023-11-30 04:28:41.018878: Current learning rate: 0.00879 
2023-11-30 04:32:27.142988: train_loss -0.8917 
2023-11-30 04:32:27.143199: val_loss -0.6844 
2023-11-30 04:32:27.143321: Pseudo dice [0.8476] 
2023-11-30 04:32:27.143415: Epoch time: 226.13 s 
2023-11-30 04:32:27.143497: Yayy! New best EMA pseudo Dice: 0.8474 
2023-11-30 04:32:29.832226:  
2023-11-30 04:32:29.832351: Epoch 134 
2023-11-30 04:32:29.832515: Current learning rate: 0.00879 
2023-11-30 04:36:14.483185: train_loss -0.8918 
2023-11-30 04:36:14.483410: val_loss -0.6626 
2023-11-30 04:36:14.483532: Pseudo dice [0.8482] 
2023-11-30 04:36:14.483628: Epoch time: 224.65 s 
2023-11-30 04:36:14.483710: Yayy! New best EMA pseudo Dice: 0.8475 
2023-11-30 04:36:17.198997:  
2023-11-30 04:36:17.199169: Epoch 135 
2023-11-30 04:36:17.199316: Current learning rate: 0.00878 
2023-11-30 04:39:58.411410: train_loss -0.8968 
2023-11-30 04:39:58.411655: val_loss -0.6783 
2023-11-30 04:39:58.411762: Pseudo dice [0.848] 
2023-11-30 04:39:58.411856: Epoch time: 221.21 s 
2023-11-30 04:39:58.411939: Yayy! New best EMA pseudo Dice: 0.8475 
2023-11-30 04:40:01.110210:  
2023-11-30 04:40:01.110565: Epoch 136 
2023-11-30 04:40:01.110708: Current learning rate: 0.00877 
2023-11-30 04:43:45.412776: train_loss -0.8945 
2023-11-30 04:43:45.412980: val_loss -0.6862 
2023-11-30 04:43:45.413100: Pseudo dice [0.85] 
2023-11-30 04:43:45.413195: Epoch time: 224.3 s 
2023-11-30 04:43:45.413277: Yayy! New best EMA pseudo Dice: 0.8478 
2023-11-30 04:43:48.266369:  
2023-11-30 04:43:48.266666: Epoch 137 
2023-11-30 04:43:48.266923: Current learning rate: 0.00876 
2023-11-30 04:47:34.485516: train_loss -0.8946 
2023-11-30 04:47:34.485802: val_loss -0.6775 
2023-11-30 04:47:34.485910: Pseudo dice [0.8447] 
2023-11-30 04:47:34.486020: Epoch time: 226.22 s 
2023-11-30 04:47:35.950395:  
2023-11-30 04:47:35.950551: Epoch 138 
2023-11-30 04:47:35.950686: Current learning rate: 0.00875 
2023-11-30 04:51:20.766875: train_loss -0.8944 
2023-11-30 04:51:20.767115: val_loss -0.6734 
2023-11-30 04:51:20.767237: Pseudo dice [0.8465] 
2023-11-30 04:51:20.767331: Epoch time: 224.82 s 
2023-11-30 04:51:22.232213:  
2023-11-30 04:51:22.232387: Epoch 139 
2023-11-30 04:51:22.232520: Current learning rate: 0.00874 
2023-11-30 04:55:05.503822: train_loss -0.8934 
2023-11-30 04:55:05.504044: val_loss -0.6766 
2023-11-30 04:55:05.504149: Pseudo dice [0.8433] 
2023-11-30 04:55:05.504243: Epoch time: 223.27 s 
2023-11-30 04:55:06.970413:  
2023-11-30 04:55:06.970551: Epoch 140 
2023-11-30 04:55:06.970699: Current learning rate: 0.00873 
2023-11-30 04:58:53.850687: train_loss -0.8966 
2023-11-30 04:58:53.850896: val_loss -0.679 
2023-11-30 04:58:53.851017: Pseudo dice [0.8481] 
2023-11-30 04:58:53.851111: Epoch time: 226.88 s 
2023-11-30 04:58:55.373446:  
2023-11-30 04:58:55.373744: Epoch 141 
2023-11-30 04:58:55.373916: Current learning rate: 0.00872 
2023-11-30 05:02:36.869861: train_loss -0.895 
2023-11-30 05:02:36.870089: val_loss -0.6849 
2023-11-30 05:02:36.870213: Pseudo dice [0.849] 
2023-11-30 05:02:36.870323: Epoch time: 221.5 s 
2023-11-30 05:02:38.558594:  
2023-11-30 05:02:38.558718: Epoch 142 
2023-11-30 05:02:38.558882: Current learning rate: 0.00871 
2023-11-30 05:06:22.532407: train_loss -0.8937 
2023-11-30 05:06:22.532669: val_loss -0.6778 
2023-11-30 05:06:22.532781: Pseudo dice [0.848] 
2023-11-30 05:06:22.532876: Epoch time: 223.98 s 
2023-11-30 05:06:24.024878:  
2023-11-30 05:06:24.025287: Epoch 143 
2023-11-30 05:06:24.025574: Current learning rate: 0.0087 
2023-11-30 05:10:07.014955: train_loss -0.8919 
2023-11-30 05:10:07.015154: val_loss -0.6741 
2023-11-30 05:10:07.015274: Pseudo dice [0.8454] 
2023-11-30 05:10:07.015367: Epoch time: 222.99 s 
2023-11-30 05:10:08.480424:  
2023-11-30 05:10:08.480547: Epoch 144 
2023-11-30 05:10:08.480709: Current learning rate: 0.00869 
2023-11-30 05:13:53.217011: train_loss -0.8977 
2023-11-30 05:13:53.217219: val_loss -0.6825 
2023-11-30 05:13:53.217378: Pseudo dice [0.8468] 
2023-11-30 05:13:53.217484: Epoch time: 224.74 s 
2023-11-30 05:13:54.710519:  
2023-11-30 05:13:54.710667: Epoch 145 
2023-11-30 05:13:54.710830: Current learning rate: 0.00868 
2023-11-30 05:17:39.621393: train_loss -0.8973 
2023-11-30 05:17:39.621662: val_loss -0.676 
2023-11-30 05:17:39.621783: Pseudo dice [0.8475] 
2023-11-30 05:17:39.621877: Epoch time: 224.91 s 
2023-11-30 05:17:41.143205:  
2023-11-30 05:17:41.143341: Epoch 146 
2023-11-30 05:17:41.143508: Current learning rate: 0.00868 
2023-11-30 05:21:24.398943: train_loss -0.8976 
2023-11-30 05:21:24.399161: val_loss -0.6708 
2023-11-30 05:21:24.399301: Pseudo dice [0.8461] 
2023-11-30 05:21:24.399401: Epoch time: 223.26 s 
2023-11-30 05:21:26.025042:  
2023-11-30 05:21:26.025182: Epoch 147 
2023-11-30 05:21:26.025370: Current learning rate: 0.00867 
2023-11-30 05:25:09.370893: train_loss -0.8944 
2023-11-30 05:25:09.371124: val_loss -0.6802 
2023-11-30 05:25:09.371246: Pseudo dice [0.8498] 
2023-11-30 05:25:09.371341: Epoch time: 223.35 s 
2023-11-30 05:25:10.887728:  
2023-11-30 05:25:10.887980: Epoch 148 
2023-11-30 05:25:10.888226: Current learning rate: 0.00866 
2023-11-30 05:28:54.109885: train_loss -0.8988 
2023-11-30 05:28:54.110220: val_loss -0.6713 
2023-11-30 05:28:54.110344: Pseudo dice [0.847] 
2023-11-30 05:28:54.110458: Epoch time: 223.22 s 
2023-11-30 05:28:55.625731:  
2023-11-30 05:28:55.625896: Epoch 149 
2023-11-30 05:28:55.626032: Current learning rate: 0.00865 
2023-11-30 05:32:40.906427: train_loss -0.8945 
2023-11-30 05:32:40.906632: val_loss -0.6752 
2023-11-30 05:32:40.906751: Pseudo dice [0.8486] 
2023-11-30 05:32:40.906845: Epoch time: 225.28 s 
2023-11-30 05:32:43.611906:  
2023-11-30 05:32:43.612164: Epoch 150 
2023-11-30 05:32:43.612544: Current learning rate: 0.00864 
2023-11-30 05:36:24.510422: train_loss -0.8977 
2023-11-30 05:36:24.510690: val_loss -0.663 
2023-11-30 05:36:24.510786: Pseudo dice [0.8452] 
2023-11-30 05:36:24.510881: Epoch time: 220.9 s 
2023-11-30 05:36:26.024978:  
2023-11-30 05:36:26.025095: Epoch 151 
2023-11-30 05:36:26.025273: Current learning rate: 0.00863 
2023-11-30 05:40:08.104900: train_loss -0.8962 
2023-11-30 05:40:08.105153: val_loss -0.6664 
2023-11-30 05:40:08.105276: Pseudo dice [0.8464] 
2023-11-30 05:40:08.105406: Epoch time: 222.08 s 
2023-11-30 05:40:09.727038:  
2023-11-30 05:40:09.727358: Epoch 152 
2023-11-30 05:40:09.727689: Current learning rate: 0.00862 
2023-11-30 05:43:51.534274: train_loss -0.8951 
2023-11-30 05:43:51.534555: val_loss -0.6762 
2023-11-30 05:43:51.534663: Pseudo dice [0.8465] 
2023-11-30 05:43:51.534758: Epoch time: 221.81 s 
2023-11-30 05:43:53.014896:  
2023-11-30 05:43:53.015055: Epoch 153 
2023-11-30 05:43:53.015199: Current learning rate: 0.00861 
2023-11-30 05:47:34.963926: train_loss -0.8967 
2023-11-30 05:47:34.964158: val_loss -0.6665 
2023-11-30 05:47:34.964266: Pseudo dice [0.8471] 
2023-11-30 05:47:34.964360: Epoch time: 221.95 s 
2023-11-30 05:47:36.481465:  
2023-11-30 05:47:36.481771: Epoch 154 
2023-11-30 05:47:36.481927: Current learning rate: 0.0086 
2023-11-30 05:51:16.944817: train_loss -0.8969 
2023-11-30 05:51:16.945092: val_loss -0.6764 
2023-11-30 05:51:16.945190: Pseudo dice [0.8456] 
2023-11-30 05:51:16.945361: Epoch time: 220.46 s 
2023-11-30 05:51:18.465680:  
2023-11-30 05:51:18.465961: Epoch 155 
2023-11-30 05:51:18.466221: Current learning rate: 0.00859 
2023-11-30 05:54:59.163033: train_loss -0.8973 
2023-11-30 05:54:59.163251: val_loss -0.6664 
2023-11-30 05:54:59.163372: Pseudo dice [0.8463] 
2023-11-30 05:54:59.163466: Epoch time: 220.7 s 
2023-11-30 05:55:00.667124:  
2023-11-30 05:55:00.667401: Epoch 156 
2023-11-30 05:55:00.667607: Current learning rate: 0.00858 
2023-11-30 05:58:42.425874: train_loss -0.8993 
2023-11-30 05:58:42.426188: val_loss -0.6676 
2023-11-30 05:58:42.426297: Pseudo dice [0.8484] 
2023-11-30 05:58:42.426427: Epoch time: 221.76 s 
2023-11-30 05:58:44.107150:  
2023-11-30 05:58:44.107316: Epoch 157 
2023-11-30 05:58:44.107460: Current learning rate: 0.00858 
2023-11-30 06:02:27.186241: train_loss -0.898 
2023-11-30 06:02:27.186694: val_loss -0.6819 
2023-11-30 06:02:27.186834: Pseudo dice [0.8466] 
2023-11-30 06:02:27.186972: Epoch time: 223.08 s 
2023-11-30 06:02:28.745759:  
2023-11-30 06:02:28.745931: Epoch 158 
2023-11-30 06:02:28.746061: Current learning rate: 0.00857 
2023-11-30 06:06:11.516293: train_loss -0.9008 
2023-11-30 06:06:11.516509: val_loss -0.6662 
2023-11-30 06:06:11.516616: Pseudo dice [0.845] 
2023-11-30 06:06:11.516708: Epoch time: 222.77 s 
2023-11-30 06:06:13.085331:  
2023-11-30 06:06:13.085478: Epoch 159 
2023-11-30 06:06:13.085648: Current learning rate: 0.00856 
2023-11-30 06:09:54.099822: train_loss -0.8999 
2023-11-30 06:09:54.100054: val_loss -0.6693 
2023-11-30 06:09:54.100161: Pseudo dice [0.8463] 
2023-11-30 06:09:54.100272: Epoch time: 221.02 s 
2023-11-30 06:09:55.673981:  
2023-11-30 06:09:55.674115: Epoch 160 
2023-11-30 06:09:55.674288: Current learning rate: 0.00855 
2023-11-30 06:13:38.014547: train_loss -0.8982 
2023-11-30 06:13:38.014764: val_loss -0.6727 
2023-11-30 06:13:38.014885: Pseudo dice [0.8453] 
2023-11-30 06:13:38.014981: Epoch time: 222.34 s 
2023-11-30 06:13:39.509383:  
2023-11-30 06:13:39.509504: Epoch 161 
2023-11-30 06:13:39.509668: Current learning rate: 0.00854 
2023-11-30 06:17:24.131526: train_loss -0.8999 
2023-11-30 06:17:24.131742: val_loss -0.6713 
2023-11-30 06:17:24.131863: Pseudo dice [0.8449] 
2023-11-30 06:17:24.131961: Epoch time: 224.62 s 
2023-11-30 06:17:25.826308:  
2023-11-30 06:17:25.826446: Epoch 162 
2023-11-30 06:17:25.826596: Current learning rate: 0.00853 
2023-11-30 06:21:08.288926: train_loss -0.899 
2023-11-30 06:21:08.289242: val_loss -0.6755 
2023-11-30 06:21:08.289510: Pseudo dice [0.8453] 
2023-11-30 06:21:08.289615: Epoch time: 222.46 s 
2023-11-30 06:21:09.834712:  
2023-11-30 06:21:09.834879: Epoch 163 
2023-11-30 06:21:09.835047: Current learning rate: 0.00852 
2023-11-30 06:24:51.023311: train_loss -0.9005 
2023-11-30 06:24:51.023547: val_loss -0.6731 
2023-11-30 06:24:51.023670: Pseudo dice [0.8477] 
2023-11-30 06:24:51.023766: Epoch time: 221.19 s 
2023-11-30 06:24:52.532128:  
2023-11-30 06:24:52.532392: Epoch 164 
2023-11-30 06:24:52.532559: Current learning rate: 0.00851 
2023-11-30 06:28:34.284933: train_loss -0.9001 
2023-11-30 06:28:34.285185: val_loss -0.6733 
2023-11-30 06:28:34.285295: Pseudo dice [0.8495] 
2023-11-30 06:28:34.285425: Epoch time: 221.75 s 
2023-11-30 06:28:35.764962:  
2023-11-30 06:28:35.765095: Epoch 165 
2023-11-30 06:28:35.765244: Current learning rate: 0.0085 
2023-11-30 06:32:15.935954: train_loss -0.9028 
2023-11-30 06:32:15.936255: val_loss -0.6692 
2023-11-30 06:32:15.936392: Pseudo dice [0.8433] 
2023-11-30 06:32:15.936487: Epoch time: 220.17 s 
2023-11-30 06:32:17.412621:  
2023-11-30 06:32:17.412752: Epoch 166 
2023-11-30 06:32:17.412882: Current learning rate: 0.00849 
2023-11-30 06:35:59.801925: train_loss -0.8986 
2023-11-30 06:35:59.802138: val_loss -0.6718 
2023-11-30 06:35:59.802242: Pseudo dice [0.8466] 
2023-11-30 06:35:59.802334: Epoch time: 222.39 s 
2023-11-30 06:36:01.507216:  
2023-11-30 06:36:01.507496: Epoch 167 
2023-11-30 06:36:01.507680: Current learning rate: 0.00848 
2023-11-30 06:39:40.739080: train_loss -0.9016 
2023-11-30 06:39:40.739335: val_loss -0.6733 
2023-11-30 06:39:40.739445: Pseudo dice [0.8502] 
2023-11-30 06:39:40.739555: Epoch time: 219.23 s 
2023-11-30 06:39:42.235709:  
2023-11-30 06:39:42.235880: Epoch 168 
2023-11-30 06:39:42.236064: Current learning rate: 0.00847 
2023-11-30 06:43:22.459143: train_loss -0.9022 
2023-11-30 06:43:22.459355: val_loss -0.6782 
2023-11-30 06:43:22.459461: Pseudo dice [0.8472] 
2023-11-30 06:43:22.459555: Epoch time: 220.22 s 
2023-11-30 06:43:23.995915:  
2023-11-30 06:43:23.996042: Epoch 169 
2023-11-30 06:43:23.996193: Current learning rate: 0.00847 
2023-11-30 06:47:05.951101: train_loss -0.8997 
2023-11-30 06:47:05.951317: val_loss -0.6676 
2023-11-30 06:47:05.951447: Pseudo dice [0.8465] 
2023-11-30 06:47:05.951565: Epoch time: 221.96 s 
2023-11-30 06:47:07.529820:  
2023-11-30 06:47:07.529969: Epoch 170 
2023-11-30 06:47:07.530131: Current learning rate: 0.00846 
2023-11-30 06:50:47.151924: train_loss -0.9039 
2023-11-30 06:50:47.152159: val_loss -0.663 
2023-11-30 06:50:47.152280: Pseudo dice [0.8434] 
2023-11-30 06:50:47.152486: Epoch time: 219.62 s 
2023-11-30 06:50:48.661197:  
2023-11-30 06:50:48.661370: Epoch 171 
2023-11-30 06:50:48.661533: Current learning rate: 0.00845 
2023-11-30 06:54:26.338405: train_loss -0.9042 
2023-11-30 06:54:26.338767: val_loss -0.6753 
2023-11-30 06:54:26.338884: Pseudo dice [0.8484] 
2023-11-30 06:54:26.338997: Epoch time: 217.68 s 
2023-11-30 06:54:27.996712:  
2023-11-30 06:54:27.996972: Epoch 172 
2023-11-30 06:54:27.997161: Current learning rate: 0.00844 
2023-11-30 06:58:02.564339: train_loss -0.9014 
2023-11-30 06:58:02.564514: val_loss -0.6664 
2023-11-30 06:58:02.564638: Pseudo dice [0.8498] 
2023-11-30 06:58:02.564742: Epoch time: 214.57 s 
2023-11-30 06:58:04.050741:  
2023-11-30 06:58:04.051027: Epoch 173 
2023-11-30 06:58:04.051183: Current learning rate: 0.00843 
2023-11-30 07:01:45.099173: train_loss -0.9016 
2023-11-30 07:01:45.099392: val_loss -0.6751 
2023-11-30 07:01:45.099519: Pseudo dice [0.8494] 
2023-11-30 07:01:45.099613: Epoch time: 221.05 s 
2023-11-30 07:01:46.571675:  
2023-11-30 07:01:46.571818: Epoch 174 
2023-11-30 07:01:46.571967: Current learning rate: 0.00842 
2023-11-30 07:05:26.960878: train_loss -0.9009 
2023-11-30 07:05:26.961110: val_loss -0.6544 
2023-11-30 07:05:26.961232: Pseudo dice [0.8443] 
2023-11-30 07:05:26.961392: Epoch time: 220.39 s 
2023-11-30 07:05:28.505717:  
2023-11-30 07:05:28.505877: Epoch 175 
2023-11-30 07:05:28.506042: Current learning rate: 0.00841 
2023-11-30 07:09:11.011303: train_loss -0.9018 
2023-11-30 07:09:11.011612: val_loss -0.6708 
2023-11-30 07:09:11.011752: Pseudo dice [0.8471] 
2023-11-30 07:09:11.011851: Epoch time: 222.51 s 
2023-11-30 07:09:12.516632:  
2023-11-30 07:09:12.517041: Epoch 176 
2023-11-30 07:09:12.517281: Current learning rate: 0.0084 
2023-11-30 07:12:48.465499: train_loss -0.9034 
2023-11-30 07:12:48.465755: val_loss -0.6736 
2023-11-30 07:12:48.465889: Pseudo dice [0.848] 
2023-11-30 07:12:48.465983: Epoch time: 215.95 s 
2023-11-30 07:12:50.090615:  
2023-11-30 07:12:50.090750: Epoch 177 
2023-11-30 07:12:50.090887: Current learning rate: 0.00839 
2023-11-30 07:16:27.335452: train_loss -0.9041 
2023-11-30 07:16:27.335715: val_loss -0.658 
2023-11-30 07:16:27.335846: Pseudo dice [0.846] 
2023-11-30 07:16:27.335941: Epoch time: 217.25 s 
2023-11-30 07:16:28.825820:  
2023-11-30 07:16:28.826183: Epoch 178 
2023-11-30 07:16:28.826474: Current learning rate: 0.00838 
2023-11-30 07:20:06.067950: train_loss -0.9038 
2023-11-30 07:20:06.068167: val_loss -0.6761 
2023-11-30 07:20:06.068286: Pseudo dice [0.8471] 
2023-11-30 07:20:06.068382: Epoch time: 217.24 s 
2023-11-30 07:20:07.588896:  
2023-11-30 07:20:07.589034: Epoch 179 
2023-11-30 07:20:07.589182: Current learning rate: 0.00837 
2023-11-30 07:23:50.027550: train_loss -0.903 
2023-11-30 07:23:50.027787: val_loss -0.6645 
2023-11-30 07:23:50.027897: Pseudo dice [0.8473] 
2023-11-30 07:23:50.027995: Epoch time: 222.44 s 
2023-11-30 07:23:51.558828:  
2023-11-30 07:23:51.559070: Epoch 180 
2023-11-30 07:23:51.559303: Current learning rate: 0.00836 
2023-11-30 07:27:26.510461: train_loss -0.9064 
2023-11-30 07:27:26.510707: val_loss -0.6782 
2023-11-30 07:27:26.510830: Pseudo dice [0.8483] 
2023-11-30 07:27:26.510949: Epoch time: 214.95 s 
2023-11-30 07:27:27.981742:  
2023-11-30 07:27:27.981890: Epoch 181 
2023-11-30 07:27:27.982037: Current learning rate: 0.00836 
2023-11-30 07:31:04.834098: train_loss -0.901 
2023-11-30 07:31:04.834285: val_loss -0.6629 
2023-11-30 07:31:04.834413: Pseudo dice [0.8457] 
2023-11-30 07:31:04.834523: Epoch time: 216.85 s 
2023-11-30 07:31:06.321982:  
2023-11-30 07:31:06.322114: Epoch 182 
2023-11-30 07:31:06.322282: Current learning rate: 0.00835 
2023-11-30 07:34:45.284584: train_loss -0.9062 
2023-11-30 07:34:45.284806: val_loss -0.6748 
2023-11-30 07:34:45.284911: Pseudo dice [0.85] 
2023-11-30 07:34:45.285004: Epoch time: 218.96 s 
2023-11-30 07:34:46.946510:  
2023-11-30 07:34:46.946643: Epoch 183 
2023-11-30 07:34:46.946791: Current learning rate: 0.00834 
2023-11-30 07:38:27.476410: train_loss -0.9037 
2023-11-30 07:38:27.476639: val_loss -0.6725 
2023-11-30 07:38:27.476744: Pseudo dice [0.8454] 
2023-11-30 07:38:27.476836: Epoch time: 220.53 s 
2023-11-30 07:38:28.976478:  
2023-11-30 07:38:28.976630: Epoch 184 
2023-11-30 07:38:28.976785: Current learning rate: 0.00833 
2023-11-30 07:42:05.650857: train_loss -0.904 
2023-11-30 07:42:05.651128: val_loss -0.6772 
2023-11-30 07:42:05.651264: Pseudo dice [0.8461] 
2023-11-30 07:42:05.651358: Epoch time: 216.68 s 
2023-11-30 07:42:07.138548:  
2023-11-30 07:42:07.138685: Epoch 185 
2023-11-30 07:42:07.138835: Current learning rate: 0.00832 
2023-11-30 07:45:46.092532: train_loss -0.9062 
2023-11-30 07:45:46.092737: val_loss -0.675 
2023-11-30 07:45:46.092857: Pseudo dice [0.8478] 
2023-11-30 07:45:46.092955: Epoch time: 218.96 s 
2023-11-30 07:45:47.590212:  
2023-11-30 07:45:47.590564: Epoch 186 
2023-11-30 07:45:47.590883: Current learning rate: 0.00831 
2023-11-30 07:49:25.827955: train_loss -0.9049 
2023-11-30 07:49:25.828190: val_loss -0.6747 
2023-11-30 07:49:25.828299: Pseudo dice [0.8467] 
2023-11-30 07:49:25.828393: Epoch time: 218.24 s 
2023-11-30 07:49:27.314454:  
2023-11-30 07:49:27.314806: Epoch 187 
2023-11-30 07:49:27.315073: Current learning rate: 0.0083 
2023-11-30 07:53:06.843812: train_loss -0.902 
2023-11-30 07:53:06.844029: val_loss -0.6673 
2023-11-30 07:53:06.844136: Pseudo dice [0.8443] 
2023-11-30 07:53:06.844230: Epoch time: 219.53 s 
2023-11-30 07:53:08.324891:  
2023-11-30 07:53:08.325247: Epoch 188 
2023-11-30 07:53:08.325519: Current learning rate: 0.00829 
2023-11-30 07:56:48.394889: train_loss -0.9067 
2023-11-30 07:56:48.395097: val_loss -0.6799 
2023-11-30 07:56:48.395218: Pseudo dice [0.8464] 
2023-11-30 07:56:48.395311: Epoch time: 220.07 s 
2023-11-30 07:56:49.906007:  
2023-11-30 07:56:49.906150: Epoch 189 
2023-11-30 07:56:49.906283: Current learning rate: 0.00828 
2023-11-30 08:00:29.427491: train_loss -0.9007 
2023-11-30 08:00:29.427724: val_loss -0.67 
2023-11-30 08:00:29.427847: Pseudo dice [0.849] 
2023-11-30 08:00:29.427956: Epoch time: 219.52 s 
2023-11-30 08:00:30.948259:  
2023-11-30 08:00:30.948400: Epoch 190 
2023-11-30 08:00:30.948545: Current learning rate: 0.00827 
2023-11-30 08:04:09.688487: train_loss -0.9061 
2023-11-30 08:04:09.688701: val_loss -0.6664 
2023-11-30 08:04:09.688816: Pseudo dice [0.8463] 
2023-11-30 08:04:09.688910: Epoch time: 218.74 s 
2023-11-30 08:04:11.198051:  
2023-11-30 08:04:11.198190: Epoch 191 
2023-11-30 08:04:11.198340: Current learning rate: 0.00826 
2023-11-30 08:07:50.306218: train_loss -0.9035 
2023-11-30 08:07:50.306436: val_loss -0.6689 
2023-11-30 08:07:50.306561: Pseudo dice [0.8495] 
2023-11-30 08:07:50.306653: Epoch time: 219.11 s 
2023-11-30 08:07:52.025007:  
2023-11-30 08:07:52.025258: Epoch 192 
2023-11-30 08:07:52.025474: Current learning rate: 0.00825 
2023-11-30 08:11:29.949114: train_loss -0.905 
2023-11-30 08:11:29.949406: val_loss -0.675 
2023-11-30 08:11:29.949520: Pseudo dice [0.8455] 
2023-11-30 08:11:29.949635: Epoch time: 217.93 s 
2023-11-30 08:11:31.476645:  
2023-11-30 08:11:31.476776: Epoch 193 
2023-11-30 08:11:31.476954: Current learning rate: 0.00824 
2023-11-30 08:15:08.446107: train_loss -0.9053 
2023-11-30 08:15:08.446358: val_loss -0.658 
2023-11-30 08:15:08.446496: Pseudo dice [0.8465] 
2023-11-30 08:15:08.446594: Epoch time: 216.97 s 
2023-11-30 08:15:09.982163:  
2023-11-30 08:15:09.982318: Epoch 194 
2023-11-30 08:15:09.982500: Current learning rate: 0.00824 
2023-11-30 08:18:46.886973: train_loss -0.9061 
2023-11-30 08:18:46.887174: val_loss -0.6641 
2023-11-30 08:18:46.887298: Pseudo dice [0.8483] 
2023-11-30 08:18:46.887391: Epoch time: 216.91 s 
2023-11-30 08:18:48.450703:  
2023-11-30 08:18:48.450856: Epoch 195 
2023-11-30 08:18:48.451004: Current learning rate: 0.00823 
2023-11-30 08:22:27.448464: train_loss -0.9026 
2023-11-30 08:22:27.448720: val_loss -0.6643 
2023-11-30 08:22:27.449443: Pseudo dice [0.8438] 
2023-11-30 08:22:27.449554: Epoch time: 219.0 s 
2023-11-30 08:22:29.001440:  
2023-11-30 08:22:29.001584: Epoch 196 
2023-11-30 08:22:29.001741: Current learning rate: 0.00822 
2023-11-30 08:25:57.207121: train_loss -0.9024 
2023-11-30 08:25:57.207372: val_loss -0.6648 
2023-11-30 08:25:57.207465: Pseudo dice [0.8466] 
2023-11-30 08:25:57.207559: Epoch time: 208.21 s 
2023-11-30 08:25:58.857388:  
2023-11-30 08:25:58.857529: Epoch 197 
2023-11-30 08:25:58.857673: Current learning rate: 0.00821 
2023-11-30 08:29:27.315782: train_loss -0.9029 
2023-11-30 08:29:27.316011: val_loss -0.6705 
2023-11-30 08:29:27.316118: Pseudo dice [0.8447] 
2023-11-30 08:29:27.316211: Epoch time: 208.46 s 
2023-11-30 08:29:28.851617:  
2023-11-30 08:29:28.851758: Epoch 198 
2023-11-30 08:29:28.851874: Current learning rate: 0.0082 
2023-11-30 08:32:53.980607: train_loss -0.9048 
2023-11-30 08:32:53.980837: val_loss -0.6696 
2023-11-30 08:32:53.980973: Pseudo dice [0.8421] 
2023-11-30 08:32:53.981070: Epoch time: 205.13 s 
2023-11-30 08:32:55.492631:  
2023-11-30 08:32:55.492838: Epoch 199 
2023-11-30 08:32:55.493069: Current learning rate: 0.00819 
2023-11-30 08:36:23.681556: train_loss -0.9066 
2023-11-30 08:36:23.681813: val_loss -0.6673 
2023-11-30 08:36:23.681937: Pseudo dice [0.8491] 
2023-11-30 08:36:23.682032: Epoch time: 208.19 s 
2023-11-30 08:36:26.366358:  
2023-11-30 08:36:26.366508: Epoch 200 
2023-11-30 08:36:26.366660: Current learning rate: 0.00818 
2023-11-30 08:39:58.999653: train_loss -0.9056 
2023-11-30 08:39:58.999821: val_loss -0.6615 
2023-11-30 08:39:58.999959: Pseudo dice [0.8464] 
2023-11-30 08:39:59.000055: Epoch time: 212.63 s 
2023-11-30 08:40:00.525396:  
2023-11-30 08:40:00.525542: Epoch 201 
2023-11-30 08:40:00.525758: Current learning rate: 0.00817 
2023-11-30 08:43:34.403776: train_loss -0.9038 
2023-11-30 08:43:34.404087: val_loss -0.6709 
2023-11-30 08:43:34.404349: Pseudo dice [0.8466] 
2023-11-30 08:43:34.404678: Epoch time: 213.88 s 
2023-11-30 08:43:36.100128:  
2023-11-30 08:43:36.100410: Epoch 202 
2023-11-30 08:43:36.100582: Current learning rate: 0.00816 
2023-11-30 08:47:09.288927: train_loss -0.9064 
2023-11-30 08:47:09.289193: val_loss -0.6806 
2023-11-30 08:47:09.289299: Pseudo dice [0.8474] 
2023-11-30 08:47:09.289424: Epoch time: 213.19 s 
2023-11-30 08:47:10.806485:  
2023-11-30 08:47:10.806737: Epoch 203 
2023-11-30 08:47:10.806924: Current learning rate: 0.00815 
2023-11-30 08:50:46.725871: train_loss -0.9056 
2023-11-30 08:50:46.726070: val_loss -0.6551 
2023-11-30 08:50:46.726190: Pseudo dice [0.8453] 
2023-11-30 08:50:46.726285: Epoch time: 215.92 s 
2023-11-30 08:50:48.233145:  
2023-11-30 08:50:48.233262: Epoch 204 
2023-11-30 08:50:48.233432: Current learning rate: 0.00814 
2023-11-30 08:54:23.687978: train_loss -0.9055 
2023-11-30 08:54:23.688200: val_loss -0.6622 
2023-11-30 08:54:23.688322: Pseudo dice [0.8467] 
2023-11-30 08:54:23.688417: Epoch time: 215.46 s 
2023-11-30 08:54:25.196725:  
2023-11-30 08:54:25.196859: Epoch 205 
2023-11-30 08:54:25.197011: Current learning rate: 0.00813 
2023-11-30 08:58:01.563251: train_loss -0.9055 
2023-11-30 08:58:01.563457: val_loss -0.6705 
2023-11-30 08:58:01.563577: Pseudo dice [0.8466] 
2023-11-30 08:58:01.563672: Epoch time: 216.37 s 
2023-11-30 08:58:02.975297:  
2023-11-30 08:58:02.975652: Epoch 206 
2023-11-30 08:58:02.975930: Current learning rate: 0.00813 
